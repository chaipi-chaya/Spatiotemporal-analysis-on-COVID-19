{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pollutant extraction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OgwcKixXMHrr","executionInfo":{"status":"ok","timestamp":1640179735403,"user_tz":-420,"elapsed":17682,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"ed3767d7-0fdd-4d13-93f4-b580e0947887"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"G3LZ95eeTOgb","executionInfo":{"status":"ok","timestamp":1640179739287,"user_tz":-420,"elapsed":3888,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"c5e69ba0-3a17-44b5-c876-8d08e4b8cb82"},"source":["import pandas as pd\n","\n","region = pd.read_excel('/content/drive/My Drive/COVID19_Cities/Data/county_fips_master.xlsx')\n","region['fips'] = region['fips'].astype(int).astype(str).apply(lambda x: x.zfill(5)[0:5])\n","region = region[['fips', 'region']].dropna()\n","region"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-fb58170a-e87c-4e92-8920-976cf58c0471\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fips</th>\n","      <th>region</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01001</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01003</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01005</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01007</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01009</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3141</th>\n","      <td>56037</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3142</th>\n","      <td>56039</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3143</th>\n","      <td>56041</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3144</th>\n","      <td>56043</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3145</th>\n","      <td>56045</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3143 rows Ã— 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb58170a-e87c-4e92-8920-976cf58c0471')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fb58170a-e87c-4e92-8920-976cf58c0471 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fb58170a-e87c-4e92-8920-976cf58c0471');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       fips  region\n","0     01001     3.0\n","1     01003     3.0\n","2     01005     3.0\n","3     01007     3.0\n","4     01009     3.0\n","...     ...     ...\n","3141  56037     4.0\n","3142  56039     4.0\n","3143  56041     4.0\n","3144  56043     4.0\n","3145  56045     4.0\n","\n","[3143 rows x 2 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"XbBYQIrZ_w3U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638801244218,"user_tz":-420,"elapsed":948,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"e4236dff-c702-4bef-9874-80907b882b9c"},"source":["import pandas as pd\n","\n","region = pd.read_excel('/content/drive/My Drive/COVID19_Cities/Data/county_fips_master.xlsx')\n","region['fips'] = region['fips'].astype(int).astype(str).apply(lambda x: x.zfill(5)[0:5])\n","region = region[['fips', 'region']].dropna()\n","\n","cdata = pd.read_csv(\"/content/drive/My Drive/COVID19_Cities/Data/county_data.csv\")\n","cdata = cdata.drop('Unnamed: 0', axis=1)\n","cdata['fips'] = cdata['fips'].astype(int).astype(str).apply(lambda x: x.zfill(5)[0:5])\n","cdata = cdata.merge(region, on='fips').drop_duplicates().reset_index(drop=True)\n","bufflist = cdata[cdata['population'] > 100000]['fips'].tolist()\n","print(len(bufflist))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["593\n"]}]},{"cell_type":"markdown","metadata":{"id":"s-g16fT4PZXv"},"source":["## EPA data"]},{"cell_type":"code","metadata":{"id":"NCEw5qxI1QLF"},"source":["# # https://aqs.epa.gov/aqsweb/documents/data_api.html#terms\n","# ''' \n","#     {\n","#       \"code\": \"14129\",\n","#       \"value_represented\": \"Lead (TSP) LC\"\n","#     },\n","#     {\n","#       \"code\": \"42101\",\n","#       \"value_represented\": \"Carbon monoxide\"\n","#     },\n","#     {\n","#       \"code\": \"42401\",\n","#       \"value_represented\": \"Sulfur dioxide\"\n","#     },\n","#     {\n","#       \"code\": \"42602\",\n","#       \"value_represented\": \"Nitrogen dioxide (NO2)\"\n","#     },\n","#     {\n","#       \"code\": \"44201\",\n","#       \"value_represented\": \"Ozone\"\n","#     },\n","#     {\n","#       \"code\": \"81102\",\n","#       \"value_represented\": \"PM10 Total 0-10um STP\"\n","#     },\n","#     {\n","#       \"code\": \"85129\",\n","#       \"value_represented\": \"Lead PM10 LC FRM/FEM\"\n","#     },\n","#     {\n","#       \"code\": \"88101\",\n","#       \"value_represented\": \"PM2.5 - Local Conditions\"\n","# '''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnbfMZqIjL6i"},"source":["# https://aqs.epa.gov/aqsweb/airdata/download_files.html#Annual"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J86h9DNFTSyk"},"source":["### Annual data table"]},{"cell_type":"markdown","metadata":{"id":"omY3J7NJTW_i"},"source":["#### Ozone"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"C50MgrMALYWw","executionInfo":{"status":"ok","timestamp":1638804289830,"user_tz":-420,"elapsed":3647,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"a850a372-7214-4963-ed78-a335495ebe25"},"source":["para_name = 'Ozone'\n","sample_duration = '1 HOUR'\n","pollutant_standard = 'Ozone 1-hour 1979'\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2015.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2015 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2015['State Code'] = data2015['State Code'].apply(lambda x: str(x).zfill(2))\n","data2015['County Code'] = data2015['County Code'].apply(lambda x: str(x).zfill(3))\n","data2015['FIPS Code'] = data2015['State Code'] + data2015['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2016.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2016 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2016['State Code'] = data2016['State Code'].apply(lambda x: str(x).zfill(2))\n","data2016['County Code'] = data2016['County Code'].apply(lambda x: str(x).zfill(3))\n","data2016['FIPS Code'] = data2016['State Code'] + data2016['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2017.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2017 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2017['State Code'] = data2017['State Code'].apply(lambda x: str(x).zfill(2))\n","data2017['County Code'] = data2017['County Code'].apply(lambda x: str(x).zfill(3))\n","data2017['FIPS Code'] = data2017['State Code'] + data2017['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2018.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2018 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2018['State Code'] = data2018['State Code'].apply(lambda x: str(x).zfill(2))\n","data2018['County Code'] = data2018['County Code'].apply(lambda x: str(x).zfill(3))\n","data2018['FIPS Code'] = data2018['State Code'] + data2018['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2019.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2019 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2019['State Code'] = data2019['State Code'].apply(lambda x: str(x).zfill(2))\n","data2019['County Code'] = data2019['County Code'].apply(lambda x: str(x).zfill(3))\n","data2019['FIPS Code'] = data2019['State Code'] + data2019['County Code']\n","\n","\n","ozone_data = pd.concat([data2015, data2016, data2017, data2018, data2019])\n","ozone_data = ozone_data.groupby('FIPS Code').mean()\n","ozone_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Arithmetic Mean</th>\n","    </tr>\n","    <tr>\n","      <th>FIPS Code</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>01003</th>\n","      <td>0.044720</td>\n","    </tr>\n","    <tr>\n","      <th>01033</th>\n","      <td>0.043184</td>\n","    </tr>\n","    <tr>\n","      <th>01049</th>\n","      <td>0.046979</td>\n","    </tr>\n","    <tr>\n","      <th>01051</th>\n","      <td>0.044146</td>\n","    </tr>\n","    <tr>\n","      <th>01055</th>\n","      <td>0.047167</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>72021</th>\n","      <td>0.024580</td>\n","    </tr>\n","    <tr>\n","      <th>72033</th>\n","      <td>0.016052</td>\n","    </tr>\n","    <tr>\n","      <th>72077</th>\n","      <td>0.016801</td>\n","    </tr>\n","    <tr>\n","      <th>72097</th>\n","      <td>0.010220</td>\n","    </tr>\n","    <tr>\n","      <th>80026</th>\n","      <td>0.048824</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>817 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["           Arithmetic Mean\n","FIPS Code                 \n","01003             0.044720\n","01033             0.043184\n","01049             0.046979\n","01051             0.044146\n","01055             0.047167\n","...                    ...\n","72021             0.024580\n","72033             0.016052\n","72077             0.016801\n","72097             0.010220\n","80026             0.048824\n","\n","[817 rows x 1 columns]"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"p6IiixshUbJK"},"source":["#### PM2.5"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DWATaakyUdcX","executionInfo":{"status":"ok","timestamp":1638804293137,"user_tz":-420,"elapsed":3313,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"2da2276a-0455-4955-88f4-1ca9da0e126d"},"source":["para_name = 'PM2.5 - Local Conditions'\n","sample_duration = '24 HOUR'\n","pollutant_standard = 'PM25 24-hour 2012'\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2015.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2015 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2015['State Code'] = data2015['State Code'].apply(lambda x: str(x).zfill(2))\n","data2015['County Code'] = data2015['County Code'].apply(lambda x: str(x).zfill(3))\n","data2015['FIPS Code'] = data2015['State Code'] + data2015['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2016.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2016 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2016['State Code'] = data2016['State Code'].apply(lambda x: str(x).zfill(2))\n","data2016['County Code'] = data2016['County Code'].apply(lambda x: str(x).zfill(3))\n","data2016['FIPS Code'] = data2016['State Code'] + data2016['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2017.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2017 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2017['State Code'] = data2017['State Code'].apply(lambda x: str(x).zfill(2))\n","data2017['County Code'] = data2017['County Code'].apply(lambda x: str(x).zfill(3))\n","data2017['FIPS Code'] = data2017['State Code'] + data2017['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2018.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2018 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2018['State Code'] = data2018['State Code'].apply(lambda x: str(x).zfill(2))\n","data2018['County Code'] = data2018['County Code'].apply(lambda x: str(x).zfill(3))\n","data2018['FIPS Code'] = data2018['State Code'] + data2018['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2019.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2019 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2019['State Code'] = data2019['State Code'].apply(lambda x: str(x).zfill(2))\n","data2019['County Code'] = data2019['County Code'].apply(lambda x: str(x).zfill(3))\n","data2019['FIPS Code'] = data2019['State Code'] + data2019['County Code']\n","\n","\n","pm25_data = pd.concat([data2015, data2016, data2017, data2018, data2019])\n","pm25_data = pm25_data.groupby('FIPS Code').mean()\n","pm25_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Arithmetic Mean</th>\n","    </tr>\n","    <tr>\n","      <th>FIPS Code</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>01003</th>\n","      <td>7.592025</td>\n","    </tr>\n","    <tr>\n","      <th>01027</th>\n","      <td>7.617464</td>\n","    </tr>\n","    <tr>\n","      <th>01033</th>\n","      <td>7.671337</td>\n","    </tr>\n","    <tr>\n","      <th>01049</th>\n","      <td>7.879428</td>\n","    </tr>\n","    <tr>\n","      <th>01055</th>\n","      <td>8.460855</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>72059</th>\n","      <td>6.548527</td>\n","    </tr>\n","    <tr>\n","      <th>72061</th>\n","      <td>8.511787</td>\n","    </tr>\n","    <tr>\n","      <th>72113</th>\n","      <td>8.333687</td>\n","    </tr>\n","    <tr>\n","      <th>72127</th>\n","      <td>9.547059</td>\n","    </tr>\n","    <tr>\n","      <th>78010</th>\n","      <td>7.241965</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>531 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["           Arithmetic Mean\n","FIPS Code                 \n","01003             7.592025\n","01027             7.617464\n","01033             7.671337\n","01049             7.879428\n","01055             8.460855\n","...                    ...\n","72059             6.548527\n","72061             8.511787\n","72113             8.333687\n","72127             9.547059\n","78010             7.241965\n","\n","[531 rows x 1 columns]"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"OSbJwtJ9U-Uc"},"source":["#### NO2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NwGW_17dVAPr","executionInfo":{"status":"ok","timestamp":1638804296033,"user_tz":-420,"elapsed":2902,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"32a07e10-f1b9-4f12-d4f0-e408a9cce1ce"},"source":["para_name = 'Nitrogen dioxide (NO2)'\n","sample_duration = '1 HOUR'\n","pollutant_standard = 'NO2 1-hour 2010'\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2015.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2015 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2015['State Code'] = data2015['State Code'].apply(lambda x: str(x).zfill(2))\n","data2015['County Code'] = data2015['County Code'].apply(lambda x: str(x).zfill(3))\n","data2015['FIPS Code'] = data2015['State Code'] + data2015['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2016.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2016 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2016['State Code'] = data2016['State Code'].apply(lambda x: str(x).zfill(2))\n","data2016['County Code'] = data2016['County Code'].apply(lambda x: str(x).zfill(3))\n","data2016['FIPS Code'] = data2016['State Code'] + data2016['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2017.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2017 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2017['State Code'] = data2017['State Code'].apply(lambda x: str(x).zfill(2))\n","data2017['County Code'] = data2017['County Code'].apply(lambda x: str(x).zfill(3))\n","data2017['FIPS Code'] = data2017['State Code'] + data2017['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2018.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2018 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2018['State Code'] = data2018['State Code'].apply(lambda x: str(x).zfill(2))\n","data2018['County Code'] = data2018['County Code'].apply(lambda x: str(x).zfill(3))\n","data2018['FIPS Code'] = data2018['State Code'] + data2018['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2019.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2019 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2019['State Code'] = data2019['State Code'].apply(lambda x: str(x).zfill(2))\n","data2019['County Code'] = data2019['County Code'].apply(lambda x: str(x).zfill(3))\n","data2019['FIPS Code'] = data2019['State Code'] + data2019['County Code']\n","\n","\n","no2_data = pd.concat([data2015, data2016, data2017, data2018, data2019])\n","no2_data = no2_data.groupby('FIPS Code').mean()\n","no2_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Arithmetic Mean</th>\n","    </tr>\n","    <tr>\n","      <th>FIPS Code</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>01073</th>\n","      <td>23.874042</td>\n","    </tr>\n","    <tr>\n","      <th>02090</th>\n","      <td>21.928836</td>\n","    </tr>\n","    <tr>\n","      <th>04012</th>\n","      <td>1.876745</td>\n","    </tr>\n","    <tr>\n","      <th>04013</th>\n","      <td>33.682005</td>\n","    </tr>\n","    <tr>\n","      <th>04019</th>\n","      <td>18.987787</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>56039</th>\n","      <td>4.697167</td>\n","    </tr>\n","    <tr>\n","      <th>56041</th>\n","      <td>5.020021</td>\n","    </tr>\n","    <tr>\n","      <th>56045</th>\n","      <td>11.865616</td>\n","    </tr>\n","    <tr>\n","      <th>72025</th>\n","      <td>28.683903</td>\n","    </tr>\n","    <tr>\n","      <th>72061</th>\n","      <td>16.671286</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>288 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["           Arithmetic Mean\n","FIPS Code                 \n","01073            23.874042\n","02090            21.928836\n","04012             1.876745\n","04013            33.682005\n","04019            18.987787\n","...                    ...\n","56039             4.697167\n","56041             5.020021\n","56045            11.865616\n","72025            28.683903\n","72061            16.671286\n","\n","[288 rows x 1 columns]"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"0Gy4FSBwVYB4"},"source":["#### SO2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bwm4Yvo5VXaJ","executionInfo":{"status":"ok","timestamp":1638804299671,"user_tz":-420,"elapsed":3308,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"9940d5c7-91a0-4f81-8b82-36ecc42f385c"},"source":["para_name = 'Sulfur dioxide'\n","sample_duration = '1 HOUR'\n","pollutant_standard = 'SO2 1-hour 2010'\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2015.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2015 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2015['State Code'] = data2015['State Code'].apply(lambda x: str(x).zfill(2))\n","data2015['County Code'] = data2015['County Code'].apply(lambda x: str(x).zfill(3))\n","data2015['FIPS Code'] = data2015['State Code'] + data2015['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2016.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2016 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2016['State Code'] = data2016['State Code'].apply(lambda x: str(x).zfill(2))\n","data2016['County Code'] = data2016['County Code'].apply(lambda x: str(x).zfill(3))\n","data2016['FIPS Code'] = data2016['State Code'] + data2016['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2017.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2017 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2017['State Code'] = data2017['State Code'].apply(lambda x: str(x).zfill(2))\n","data2017['County Code'] = data2017['County Code'].apply(lambda x: str(x).zfill(3))\n","data2017['FIPS Code'] = data2017['State Code'] + data2017['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2018.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2018 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2018['State Code'] = data2018['State Code'].apply(lambda x: str(x).zfill(2))\n","data2018['County Code'] = data2018['County Code'].apply(lambda x: str(x).zfill(3))\n","data2018['FIPS Code'] = data2018['State Code'] + data2018['County Code']\n","\n","pollutant_data = pd.read_csv('/content/drive/My Drive/COVID19_Cities/Data/pollutant data/annual_conc_by_monitor_2019.csv')\n","pollutant_data = pollutant_data[['State Code', 'County Code', 'Parameter Name', 'Sample Duration', 'Pollutant Standard', 'Arithmetic Mean']]\n","\n","data2019 = pollutant_data[(pollutant_data['Parameter Name'] == para_name) & (pollutant_data['Sample Duration'] == sample_duration) & (pollutant_data['Pollutant Standard'] == pollutant_standard)]\n","data2019['State Code'] = data2019['State Code'].apply(lambda x: str(x).zfill(2))\n","data2019['County Code'] = data2019['County Code'].apply(lambda x: str(x).zfill(3))\n","data2019['FIPS Code'] = data2019['State Code'] + data2019['County Code']\n","\n","\n","so2_data = pd.concat([data2015, data2016, data2017, data2018, data2019])\n","so2_data = so2_data.groupby('FIPS Code').mean()\n","so2_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Arithmetic Mean</th>\n","    </tr>\n","    <tr>\n","      <th>FIPS Code</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>01073</th>\n","      <td>5.747070</td>\n","    </tr>\n","    <tr>\n","      <th>01097</th>\n","      <td>2.111769</td>\n","    </tr>\n","    <tr>\n","      <th>01117</th>\n","      <td>4.093148</td>\n","    </tr>\n","    <tr>\n","      <th>01119</th>\n","      <td>0.989757</td>\n","    </tr>\n","    <tr>\n","      <th>02090</th>\n","      <td>10.608545</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>72021</th>\n","      <td>2.878246</td>\n","    </tr>\n","    <tr>\n","      <th>72033</th>\n","      <td>2.406230</td>\n","    </tr>\n","    <tr>\n","      <th>72057</th>\n","      <td>1.898733</td>\n","    </tr>\n","    <tr>\n","      <th>72077</th>\n","      <td>8.770141</td>\n","    </tr>\n","    <tr>\n","      <th>72123</th>\n","      <td>4.281401</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>370 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["           Arithmetic Mean\n","FIPS Code                 \n","01073             5.747070\n","01097             2.111769\n","01117             4.093148\n","01119             0.989757\n","02090            10.608545\n","...                    ...\n","72021             2.878246\n","72033             2.406230\n","72057             1.898733\n","72077             8.770141\n","72123             4.281401\n","\n","[370 rows x 1 columns]"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"wwX5uS7DVoh9"},"source":["#### Combine"]},{"cell_type":"code","metadata":{"id":"1-nMS_Y0Vp4O"},"source":["ozone_data = ozone_data.rename(columns={'Arithmetic Mean': 'ozone'})\n","pm25_data = pm25_data.rename(columns={'Arithmetic Mean': 'pm25'})\n","no2_data = no2_data.rename(columns={'Arithmetic Mean': 'no2'})\n","so2_data = so2_data.rename(columns={'Arithmetic Mean': 'so2'})\n","\n","pollutant_data = ozone_data.merge(pm25_data, on='FIPS Code').merge(no2_data, on='FIPS Code').merge(so2_data, on='FIPS Code')\n","pollutant_data['FIPS'] = pollutant_data.index\n","pollutant_data.to_csv('pollutant_data.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIkRpPY9XLe-","colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"status":"ok","timestamp":1638804537357,"user_tz":-420,"elapsed":393,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"3c329627-fa94-4051-c7d5-4d4a67d9b66a"},"source":["pollutant_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ozone</th>\n","      <th>pm25</th>\n","      <th>no2</th>\n","      <th>so2</th>\n","      <th>FIPS</th>\n","    </tr>\n","    <tr>\n","      <th>FIPS Code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>01073</th>\n","      <td>0.047070</td>\n","      <td>9.525054</td>\n","      <td>23.874042</td>\n","      <td>5.747070</td>\n","      <td>01073</td>\n","    </tr>\n","    <tr>\n","      <th>02090</th>\n","      <td>0.026461</td>\n","      <td>10.849387</td>\n","      <td>21.928836</td>\n","      <td>10.608545</td>\n","      <td>02090</td>\n","    </tr>\n","    <tr>\n","      <th>04013</th>\n","      <td>0.054356</td>\n","      <td>7.750166</td>\n","      <td>33.682005</td>\n","      <td>1.880994</td>\n","      <td>04013</td>\n","    </tr>\n","    <tr>\n","      <th>04019</th>\n","      <td>0.049596</td>\n","      <td>5.818324</td>\n","      <td>18.987787</td>\n","      <td>0.390580</td>\n","      <td>04019</td>\n","    </tr>\n","    <tr>\n","      <th>05119</th>\n","      <td>0.043522</td>\n","      <td>9.876525</td>\n","      <td>19.265127</td>\n","      <td>1.656260</td>\n","      <td>05119</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>56025</th>\n","      <td>0.048387</td>\n","      <td>4.727953</td>\n","      <td>14.449601</td>\n","      <td>2.343941</td>\n","      <td>56025</td>\n","    </tr>\n","    <tr>\n","      <th>56029</th>\n","      <td>0.043852</td>\n","      <td>4.001783</td>\n","      <td>6.898295</td>\n","      <td>0.372601</td>\n","      <td>56029</td>\n","    </tr>\n","    <tr>\n","      <th>56033</th>\n","      <td>0.048371</td>\n","      <td>6.301581</td>\n","      <td>15.557472</td>\n","      <td>0.627411</td>\n","      <td>56033</td>\n","    </tr>\n","    <tr>\n","      <th>56037</th>\n","      <td>0.051089</td>\n","      <td>5.037073</td>\n","      <td>10.821568</td>\n","      <td>3.161161</td>\n","      <td>56037</td>\n","    </tr>\n","    <tr>\n","      <th>56039</th>\n","      <td>0.049701</td>\n","      <td>4.486799</td>\n","      <td>4.697167</td>\n","      <td>0.360088</td>\n","      <td>56039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>146 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["              ozone       pm25        no2        so2   FIPS\n","FIPS Code                                                  \n","01073      0.047070   9.525054  23.874042   5.747070  01073\n","02090      0.026461  10.849387  21.928836  10.608545  02090\n","04013      0.054356   7.750166  33.682005   1.880994  04013\n","04019      0.049596   5.818324  18.987787   0.390580  04019\n","05119      0.043522   9.876525  19.265127   1.656260  05119\n","...             ...        ...        ...        ...    ...\n","56025      0.048387   4.727953  14.449601   2.343941  56025\n","56029      0.043852   4.001783   6.898295   0.372601  56029\n","56033      0.048371   6.301581  15.557472   0.627411  56033\n","56037      0.051089   5.037073  10.821568   3.161161  56037\n","56039      0.049701   4.486799   4.697167   0.360088  56039\n","\n","[146 rows x 5 columns]"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["### Timeseries data table"],"metadata":{"id":"Nz2PntBWprZl"}},{"cell_type":"markdown","source":["#### Ozone"],"metadata":{"id":"mBbo-pi8rdcH"}},{"cell_type":"code","source":["t = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_44201_2015.csv')\n","t['Pollutant Standard'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiI3US6ojmaW","executionInfo":{"status":"ok","timestamp":1640183655804,"user_tz":-420,"elapsed":2856,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"c9035673-38e2-4093-8484-837a1cca60fa"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ozone 8-hour 2015    386404\n","Name: Pollutant Standard, dtype: int64"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["t['Sample Duration'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lV9lue8zjpmh","executionInfo":{"status":"ok","timestamp":1640183655805,"user_tz":-420,"elapsed":11,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"a6bf9cf8-a7b9-417a-b0b9-d8e218c77a90"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8-HR RUN AVG BEGIN HOUR    386404\n","Name: Sample Duration, dtype: int64"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["import pandas as pd\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_44201_2015.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips = pd.concat([data_fips, data_fip[fip]], axis=1)\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_44201_2016.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_44201_2017.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_44201_2018.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_44201_2019.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_fips.to_csv('ozone_timeseries_data.csv')"],"metadata":{"id":"Tx-JF2_NpuvY","executionInfo":{"status":"ok","timestamp":1640183805455,"user_tz":-420,"elapsed":149659,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["#### SO2"],"metadata":{"id":"XmdY4K3Bcvzr"}},{"cell_type":"code","source":["t = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42401_2015.csv')\n","t['Pollutant Standard'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZU2ED-9ciRRW","executionInfo":{"status":"ok","timestamp":1640183806740,"user_tz":-420,"elapsed":1307,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"9dc3baa5-90c9-4033-b42f-d346cb9b68e1"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SO2 1-hour 2010    160651\n","SO2 3-hour 1971    160451\n","Name: Pollutant Standard, dtype: int64"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["t['Sample Duration'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV3lgPWgj1QH","executionInfo":{"status":"ok","timestamp":1640183806741,"user_tz":-420,"elapsed":8,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"032dd808-7b48-4006-82a2-ab62328289cc"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1 HOUR          160651\n","3-HR BLK AVG    160451\n","Name: Sample Duration, dtype: int64"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["import pandas as pd\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42401_2015.csv')\n","data_201x = data_201x[data_201x['Pollutant Standard'] == 'SO2 1-hour 2010']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips = pd.concat([data_fips, data_fip[fip]], axis=1)\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42401_2016.csv')\n","data_201x = data_201x[data_201x['Pollutant Standard'] == 'SO2 1-hour 2010']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42401_2017.csv')\n","data_201x = data_201x[data_201x['Pollutant Standard'] == 'SO2 1-hour 2010']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42401_2018.csv')\n","data_201x = data_201x[data_201x['Pollutant Standard'] == 'SO2 1-hour 2010']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42401_2019.csv')\n","data_201x = data_201x[data_201x['Pollutant Standard'] == 'SO2 1-hour 2010']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_fips.to_csv('so2_timeseries_data.csv')"],"metadata":{"id":"3tQDsSx5cy8B","executionInfo":{"status":"ok","timestamp":1640183847608,"user_tz":-420,"elapsed":40871,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["#### NO2"],"metadata":{"id":"SylCRsBUc8x7"}},{"cell_type":"code","source":["t = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42602_2015.csv')\n","t['Pollutant Standard'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"my0uXVV9ixuA","executionInfo":{"status":"ok","timestamp":1640183848557,"user_tz":-420,"elapsed":968,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"b57c8c66-0ef5-45db-ddbc-c51750484a75"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NO2 1-hour 2010    154940\n","Name: Pollutant Standard, dtype: int64"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["t['Sample Duration'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYYvhPyPj4LA","executionInfo":{"status":"ok","timestamp":1640183848558,"user_tz":-420,"elapsed":8,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"08e5f0ab-411b-474c-bfd0-d768946a7aa2"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1 HOUR    154940\n","Name: Sample Duration, dtype: int64"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["import pandas as pd\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42602_2015.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips = pd.concat([data_fips, data_fip[fip]], axis=1)\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42602_2016.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42602_2017.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42602_2018.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_42602_2019.csv')\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_fips.to_csv('no2_timeseries_data.csv')"],"metadata":{"id":"P8bWG6wxdKiE","executionInfo":{"status":"ok","timestamp":1640183878408,"user_tz":-420,"elapsed":29854,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["#### PM2.5"],"metadata":{"id":"SWXi5xYTdSvm"}},{"cell_type":"code","source":["t = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_88101_2015.csv')\n","t['Pollutant Standard'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJZV_QZijTL0","executionInfo":{"status":"ok","timestamp":1640183879844,"user_tz":-420,"elapsed":1457,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"5e1d7fa8-93f2-4833-dcf0-b849f09af45d"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PM25 24-hour 2012    242468\n","Name: Pollutant Standard, dtype: int64"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["t['Sample Duration'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mZdTddYoj53Z","executionInfo":{"status":"ok","timestamp":1640183879845,"user_tz":-420,"elapsed":8,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"10772f01-f82a-4c6c-a7dd-5496cce0eb8a"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1 HOUR           132399\n","24-HR BLK AVG    129112\n","24 HOUR          113356\n","Name: Sample Duration, dtype: int64"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["import pandas as pd\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_88101_2015.csv')\n","data_201x = data_201x[data_201x['Sample Duration'] == '1 HOUR']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips = pd.concat([data_fips, data_fip[fip]], axis=1)\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_88101_2016.csv')\n","data_201x = data_201x[data_201x['Sample Duration'] == '1 HOUR']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_88101_2017.csv')\n","data_201x = data_201x[data_201x['Sample Duration'] == '1 HOUR']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_88101_2018.csv')\n","data_201x = data_201x[data_201x['Sample Duration'] == '1 HOUR']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_201x = pd.read_csv('/content/drive/MyDrive/COVID19_Cities/Data/timeseries data/daily_88101_2019.csv')\n","data_201x = data_201x[data_201x['Sample Duration'] == '1 HOUR']\n","data_201x['fips'] = data_201x['State Code'].astype(str).str.zfill(2) + data_201x['County Code'].astype(str).str.zfill(3)\n","fips_list = data_201x['fips'].unique().tolist()\n","\n","data_fips_201x = pd.DataFrame()\n","\n","data_201x['Date Local'] = pd.to_datetime(data_201x['Date Local'], errors='coerce')\n","data_fips_201x['Date Local'] = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","data_fips_201x.index = data_201x.groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean().index\n","\n","for fip in fips_list:\n","  data_fip = pd.DataFrame(data_201x[data_201x['fips'] == fip].groupby(pd.Grouper(key='Date Local', freq='W-MON')).mean()['Arithmetic Mean']).rename(columns={'Arithmetic Mean': fip})\n","  data_fips_201x = pd.concat([data_fips_201x, data_fip[fip]], axis=1)\n","\n","data_fips = pd.concat([data_fips, data_fips_201x])\n","\n","data_fips.to_csv('pm25_timeseries_data.csv')"],"metadata":{"id":"vT53naEidUI5","executionInfo":{"status":"ok","timestamp":1640184051303,"user_tz":-420,"elapsed":70161,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CLWdfhnSUkNP"},"source":["### Test API"]},{"cell_type":"markdown","metadata":{"id":"ENTvcvHFf24D"},"source":["#### PM2.5"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zyDuwQxYItD","executionInfo":{"status":"ok","timestamp":1638722801864,"user_tz":-420,"elapsed":2535,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"ba3c35b1-0ac8-4015-aa46-bc779cc6def8"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101&bdate=20160101&edate=20161231&state=04&county=013\n","years = ['2015', '2016', '2017', '2018', '2019']\n","fip = \"04013\"\n","for year in years:\n","  url = \"https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101&bdate=\"+year+\"0101&edate=\"+year+\"1231&state=04&county=013\"\n","  resp = requests.get(url=url, timeout=10)\n","  data = resp.json()\n","\n","  val = []\n","\n","  listdata = data['Data']\n","  for j in listdata:\n","    if (j['pollutant_standard'] == \"PM25 24-hour 2012\") and (j['sample_duration'] == \"24 HOUR\"):\n","      val.append(j['arithmetic_mean'])\n","  print(year,val)\n","  print(year,sum(val)/len(val))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2015 [8.125, 8.038739, 4.661702, 4.770175]\n","2015 6.398904\n","2016 [13.151613, 7.839316, 8.503333, 7.576471]\n","2016 9.26768325\n","2017 [9.543333, 8.424786, 7.721311, 8.052459]\n","2017 8.43547225\n","2018 [9.635484, 8.238525, 7.721429, 7.426667]\n","2018 8.25552625\n","2019 [7.43, 6.963025, 5.62459, 5.555357]\n","2019 6.393243\n"]}]},{"cell_type":"markdown","metadata":{"id":"DRwiHzKCf5pX"},"source":["#### NO2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_k7NDNsf2Ec","executionInfo":{"status":"ok","timestamp":1638723009836,"user_tz":-420,"elapsed":2349,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"b9b64e4c-22f8-41f3-c759-11ac8d05325a"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=42602&bdate=20160101&edate=20161231&state=04&county=013\n","years = ['2015', '2016', '2017', '2018', '2019']\n","fip = \"04013\"\n","for year in years:\n","  url = \"https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=42602&bdate=\"+year+\"0101&edate=\"+year+\"1231&state=04&county=013\"\n","  resp = requests.get(url=url, timeout=10)\n","  data = resp.json()\n","\n","  val = []\n","\n","  listdata = data['Data']\n","  for j in listdata:\n","    if (j['pollutant_standard'] == \"NO2 1-hour 2010\") and (j['sample_duration'] == \"1 HOUR\"):\n","      val.append(j['arithmetic_mean'])\n","  print(year,val)\n","  print(year,sum(val)/len(val))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2015 [34.969863, 37.30618, 40.472222, 30.253086, 45.016529, 36.821918, 16.804945]\n","2015 34.52067757142857\n","2016 [34.387978, 36.85124, 41.201183, 30.429513, 45.434426, 37.48895, 15.676712]\n","2016 34.49571457142857\n","2017 [35.238356, 38.561644, 32.684516, 46.489011, 39.879452, 17.38253]\n","2017 35.0392515\n","2018 [34.243836, 36.764384, 31.977747, 43.275281, 36.065753, 17.953039]\n","2018 33.38000666666667\n","2019 [30.731302, 34.25419, 29.32259, 39.143333, 33.632877, 17.109589]\n","2019 30.69898016666667\n"]}]},{"cell_type":"markdown","metadata":{"id":"9hwzFFLkgiii"},"source":["#### SO2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD9k5Z8BhA40","executionInfo":{"status":"ok","timestamp":1638723257441,"user_tz":-420,"elapsed":2304,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"88f74e05-dcfd-4b26-92b7-e4ac33e76d69"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=42401&bdate=20160101&edate=20161231&state=04&county=013\n","years = ['2015', '2016', '2017', '2018', '2019']\n","fip = \"04013\"\n","for year in years:\n","  url = \"https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=42401&bdate=\"+year+\"0101&edate=\"+year+\"1231&state=04&county=013\"\n","  resp = requests.get(url=url, timeout=10)\n","  data = resp.json()\n","\n","  val = []\n","\n","  listdata = data['Data']\n","  for j in listdata:\n","    if (j['pollutant_standard'] == \"SO2 1-hour 2010\") and (j['sample_duration'] == \"1 HOUR\"):\n","      val.append(j['arithmetic_mean'])\n","  print(year,val)\n","  print(year,sum(val)/len(val))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2015 [2.016438, 2.303621, 1.798867]\n","2015 2.039642\n","2016 [1.800546, 1.802198, 1.249527]\n","2016 1.6174236666666666\n","2017 [2.493113, 2.222841, 2.382353]\n","2017 2.3661023333333335\n","2018 [2.187328, 2.096317, 1.264857]\n","2018 1.8495006666666667\n","2019 [1.432877, 1.808219, 1.355801]\n","2019 1.532299\n"]}]},{"cell_type":"markdown","metadata":{"id":"xnGD2_MDhNQG"},"source":["#### O3"]},{"cell_type":"code","metadata":{"id":"GtaAKJT6hPB8"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=44201&bdate=20160101&edate=20161231&state=04&county=013\n","years = ['2015', '2016', '2017', '2018', '2019']\n","fip = \"04013\"\n","for year in years:\n","  url = \"https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=44201&bdate=\"+year+\"0101&edate=\"+year+\"1231&state=04&county=013\"\n","  resp = requests.get(url=url, timeout=10)\n","  data = resp.json()\n","\n","  val = []\n","\n","  listdata = data['Data']\n","  for j in listdata:\n","    if (j['pollutant_standard'] == \"Ozone 1-hour 1979\") and (j['sample_duration'] == \"1 HOUR\"):\n","      val.append(j['arithmetic_mean'])\n","  print(year,val)\n","  print(year,sum(val)/len(val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrzyhxSGaGu5","executionInfo":{"status":"ok","timestamp":1638721437205,"user_tz":-420,"elapsed":975,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"26c4c33f-dcba-4495-dd9a-5d1799265c9d"},"source":["# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101&bdate=20160101&edate=20161231&state=04&county=013\n","url = \"https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101&bdate=20160101&edate=20161231&state=04&county=013\"\n","resp = requests.get(url=url, timeout=10)\n","data = resp.json()\n","\n","val = []\n","\n","listdata = data['Data']\n","for j in listdata:\n","  val.append(j['arithmetic_mean'])\n","\n","print('2016',sum(val)/len(val))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2016 8.548508499999997\n"]}]},{"cell_type":"code","metadata":{"id":"sumG3DBkaG_t"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6veW98DGaHyF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9JnK_601dV9","executionInfo":{"status":"ok","timestamp":1627313787728,"user_tz":240,"elapsed":342966,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"798793f1-d4ab-4ab8-a6f6-f09608416d9a"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/annualData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","rows_list = []\n","n = 0\n","location = pd.DataFrame(columns=['fips', 'lat', 'long', 'site_address', 'local_site_name', 'state', 'county', 'city'])\n","for i in range(0, len(bufflist)):\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='42602',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=bufflist[i][0:2],\n","        county=bufflist[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=10)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      val = []\n","      loc = []\n","      listdata = data['Data']\n","      for j in listdata:\n","        val.append(j['arithmetic_mean'])\n","        loc.append({'fips' : bufflist[i], 'lat': j['latitude'], 'long': j['longitude'], 'site_address': j['site_address'], 'local_site_name': j['local_site_name'], 'state': j['state'], 'county': j['county'], 'city': j['city']})\n","      # val\n","      location = location.append(loc)\n","      rows_list.append({'no': np.mean(val), 'year': year, 'fips': bufflist[i]})\n","    except:\n","      print('Problem with '+ bufflist[i] + ' year ' + year)\n","  if (i % 100 == 0) and (i != 0):\n","    nodf = pd.DataFrame(rows_list)\n","    rows_list = []\n","    t = nodf.groupby('fips').mean()\n","    t = t.dropna()\n","    t.to_csv('no_'+str(n)+'.csv') \n","    n += 1\n","\n","nodf = pd.DataFrame(rows_list)\n","t = nodf.groupby('fips').mean()\n","t = t.dropna()\n","t.to_csv('no_'+str(n)+'.csv') \n","n += 1\n","\n","location = location.drop_duplicates()\n","location.to_csv('no_location.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 2015\n","0 2016\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["0 2017\n","0 2018\n","0 2019\n","1 2015\n","1 2016\n","1 2017\n","1 2018\n","1 2019\n","2 2015\n","2 2016\n","2 2017\n","2 2018\n","2 2019\n","3 2015\n","3 2016\n","3 2017\n","3 2018\n","3 2019\n","4 2015\n","4 2016\n","4 2017\n","4 2018\n","4 2019\n","5 2015\n","5 2016\n","5 2017\n","5 2018\n","5 2019\n","6 2015\n","6 2016\n","6 2017\n","6 2018\n","6 2019\n","7 2015\n","7 2016\n","7 2017\n","7 2018\n","7 2019\n","8 2015\n","8 2016\n","8 2017\n","8 2018\n","8 2019\n","9 2015\n","9 2016\n","9 2017\n","9 2018\n","9 2019\n","10 2015\n","10 2016\n","10 2017\n","10 2018\n","10 2019\n","11 2015\n","11 2016\n","11 2017\n","11 2018\n","11 2019\n","12 2015\n","12 2016\n","12 2017\n","12 2018\n","12 2019\n","13 2015\n","13 2016\n","13 2017\n","13 2018\n","13 2019\n","14 2015\n","14 2016\n","14 2017\n","14 2018\n","14 2019\n","15 2015\n","15 2016\n","15 2017\n","15 2018\n","15 2019\n","16 2015\n","16 2016\n","16 2017\n","16 2018\n","16 2019\n","17 2015\n","17 2016\n","17 2017\n","17 2018\n","17 2019\n","18 2015\n","18 2016\n","18 2017\n","18 2018\n","18 2019\n","19 2015\n","19 2016\n","19 2017\n","19 2018\n","19 2019\n","20 2015\n","20 2016\n","20 2017\n","20 2018\n","20 2019\n","21 2015\n","21 2016\n","21 2017\n","21 2018\n","21 2019\n","22 2015\n","22 2016\n","22 2017\n","22 2018\n","22 2019\n","23 2015\n","23 2016\n","23 2017\n","23 2018\n","23 2019\n","24 2015\n","24 2016\n","24 2017\n","24 2018\n","24 2019\n","25 2015\n","25 2016\n","25 2017\n","25 2018\n","25 2019\n","26 2015\n","26 2016\n","26 2017\n","26 2018\n","26 2019\n","27 2015\n","27 2016\n","27 2017\n","27 2018\n","27 2019\n","28 2015\n","28 2016\n","28 2017\n","28 2018\n","28 2019\n","29 2015\n","29 2016\n","29 2017\n","29 2018\n","29 2019\n","30 2015\n","30 2016\n","30 2017\n","30 2018\n","30 2019\n","31 2015\n","31 2016\n","31 2017\n","31 2018\n","31 2019\n","32 2015\n","32 2016\n","32 2017\n","32 2018\n","32 2019\n","33 2015\n","33 2016\n","33 2017\n","33 2018\n","33 2019\n","34 2015\n","34 2016\n","34 2017\n","34 2018\n","34 2019\n","35 2015\n","35 2016\n","35 2017\n","35 2018\n","35 2019\n","36 2015\n","36 2016\n","36 2017\n","36 2018\n","36 2019\n","37 2015\n","37 2016\n","37 2017\n","37 2018\n","37 2019\n","38 2015\n","38 2016\n","38 2017\n","38 2018\n","38 2019\n","39 2015\n","39 2016\n","39 2017\n","39 2018\n","39 2019\n","40 2015\n","40 2016\n","40 2017\n","40 2018\n","40 2019\n","41 2015\n","41 2016\n","41 2017\n","41 2018\n","41 2019\n","42 2015\n","42 2016\n","42 2017\n","42 2018\n","42 2019\n","43 2015\n","43 2016\n","43 2017\n","43 2018\n","43 2019\n","44 2015\n","44 2016\n","44 2017\n","44 2018\n","44 2019\n","45 2015\n","45 2016\n","45 2017\n","45 2018\n","45 2019\n","46 2015\n","46 2016\n","46 2017\n","46 2018\n","46 2019\n","47 2015\n","47 2016\n","47 2017\n","47 2018\n","47 2019\n","48 2015\n","48 2016\n","48 2017\n","48 2018\n","48 2019\n","49 2015\n","49 2016\n","49 2017\n","49 2018\n","49 2019\n","50 2015\n","50 2016\n","50 2017\n","50 2018\n","50 2019\n","51 2015\n","51 2016\n","51 2017\n","51 2018\n","51 2019\n","52 2015\n","52 2016\n","52 2017\n","52 2018\n","52 2019\n","53 2015\n","53 2016\n","53 2017\n","53 2018\n","53 2019\n","54 2015\n","54 2016\n","54 2017\n","54 2018\n","54 2019\n","55 2015\n","55 2016\n","55 2017\n","55 2018\n","55 2019\n","56 2015\n","56 2016\n","56 2017\n","56 2018\n","56 2019\n","57 2015\n","57 2016\n","57 2017\n","57 2018\n","57 2019\n","58 2015\n","58 2016\n","58 2017\n","58 2018\n","58 2019\n","59 2015\n","59 2016\n","59 2017\n","59 2018\n","59 2019\n","60 2015\n","60 2016\n","60 2017\n","60 2018\n","60 2019\n","61 2015\n","61 2016\n","61 2017\n","61 2018\n","61 2019\n","62 2015\n","62 2016\n","62 2017\n","62 2018\n","62 2019\n","63 2015\n","63 2016\n","63 2017\n","63 2018\n","63 2019\n","64 2015\n","64 2016\n","64 2017\n","64 2018\n","64 2019\n","65 2015\n","65 2016\n","65 2017\n","65 2018\n","65 2019\n","66 2015\n","66 2016\n","66 2017\n","66 2018\n","66 2019\n","67 2015\n","67 2016\n","67 2017\n","67 2018\n","67 2019\n","68 2015\n","68 2016\n","68 2017\n","68 2018\n","68 2019\n","69 2015\n","69 2016\n","69 2017\n","69 2018\n","69 2019\n","70 2015\n","70 2016\n","70 2017\n","70 2018\n","70 2019\n","71 2015\n","71 2016\n","71 2017\n","71 2018\n","71 2019\n","72 2015\n","72 2016\n","72 2017\n","72 2018\n","72 2019\n","73 2015\n","73 2016\n","73 2017\n","73 2018\n","73 2019\n","74 2015\n","74 2016\n","74 2017\n","74 2018\n","74 2019\n","75 2015\n","75 2016\n","75 2017\n","75 2018\n","75 2019\n","76 2015\n","76 2016\n","76 2017\n","76 2018\n","76 2019\n","77 2015\n","77 2016\n","77 2017\n","77 2018\n","77 2019\n","78 2015\n","78 2016\n","78 2017\n","78 2018\n","78 2019\n","79 2015\n","79 2016\n","79 2017\n","79 2018\n","79 2019\n","80 2015\n","80 2016\n","80 2017\n","80 2018\n","80 2019\n","81 2015\n","81 2016\n","81 2017\n","81 2018\n","81 2019\n","82 2015\n","82 2016\n","82 2017\n","82 2018\n","82 2019\n","83 2015\n","83 2016\n","83 2017\n","83 2018\n","83 2019\n","84 2015\n","84 2016\n","84 2017\n","84 2018\n","84 2019\n","85 2015\n","85 2016\n","85 2017\n","85 2018\n","85 2019\n","86 2015\n","86 2016\n","86 2017\n","86 2018\n","86 2019\n","87 2015\n","87 2016\n","87 2017\n","87 2018\n","87 2019\n","88 2015\n","88 2016\n","88 2017\n","88 2018\n","88 2019\n","89 2015\n","89 2016\n","89 2017\n","89 2018\n","89 2019\n","90 2015\n","90 2016\n","90 2017\n","90 2018\n","90 2019\n","91 2015\n","91 2016\n","91 2017\n","91 2018\n","91 2019\n","92 2015\n","92 2016\n","92 2017\n","92 2018\n","92 2019\n","93 2015\n","93 2016\n","93 2017\n","93 2018\n","93 2019\n","94 2015\n","94 2016\n","94 2017\n","94 2018\n","94 2019\n","95 2015\n","95 2016\n","95 2017\n","95 2018\n","95 2019\n","96 2015\n","96 2016\n","96 2017\n","96 2018\n","96 2019\n","97 2015\n","97 2016\n","97 2017\n","97 2018\n","97 2019\n","98 2015\n","98 2016\n","98 2017\n","98 2018\n","98 2019\n","99 2015\n","99 2016\n","99 2017\n","99 2018\n","99 2019\n","100 2015\n","100 2016\n","100 2017\n","100 2018\n","100 2019\n","101 2015\n","101 2016\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["101 2017\n","101 2018\n","101 2019\n","102 2015\n","102 2016\n","102 2017\n","102 2018\n","102 2019\n","103 2015\n","103 2016\n","103 2017\n","103 2018\n","103 2019\n","104 2015\n","104 2016\n","104 2017\n","104 2018\n","104 2019\n","105 2015\n","105 2016\n","105 2017\n","105 2018\n","105 2019\n","106 2015\n","106 2016\n","106 2017\n","106 2018\n","106 2019\n","107 2015\n","107 2016\n","107 2017\n","107 2018\n","107 2019\n","108 2015\n","108 2016\n","108 2017\n","108 2018\n","108 2019\n","109 2015\n","109 2016\n","109 2017\n","109 2018\n","109 2019\n","110 2015\n","110 2016\n","110 2017\n","110 2018\n","110 2019\n","111 2015\n","111 2016\n","111 2017\n","111 2018\n","111 2019\n","112 2015\n","112 2016\n","112 2017\n","112 2018\n","112 2019\n","113 2015\n","113 2016\n","113 2017\n","113 2018\n","113 2019\n","114 2015\n","114 2016\n","114 2017\n","114 2018\n","114 2019\n","115 2015\n","115 2016\n","115 2017\n","115 2018\n","115 2019\n","116 2015\n","116 2016\n","116 2017\n","116 2018\n","116 2019\n","117 2015\n","117 2016\n","117 2017\n","117 2018\n","117 2019\n","118 2015\n","118 2016\n","118 2017\n","118 2018\n","118 2019\n","119 2015\n","119 2016\n","119 2017\n","119 2018\n","119 2019\n","120 2015\n","120 2016\n","120 2017\n","120 2018\n","120 2019\n","121 2015\n","121 2016\n","121 2017\n","121 2018\n","121 2019\n","122 2015\n","122 2016\n","122 2017\n","122 2018\n","122 2019\n","123 2015\n","123 2016\n","123 2017\n","123 2018\n","123 2019\n","124 2015\n","124 2016\n","124 2017\n","124 2018\n","124 2019\n","125 2015\n","125 2016\n","125 2017\n","125 2018\n","125 2019\n","126 2015\n","126 2016\n","126 2017\n","126 2018\n","126 2019\n","127 2015\n","127 2016\n","127 2017\n","127 2018\n","127 2019\n","128 2015\n","128 2016\n","128 2017\n","128 2018\n","128 2019\n","129 2015\n","129 2016\n","129 2017\n","129 2018\n","129 2019\n","130 2015\n","130 2016\n","130 2017\n","130 2018\n","130 2019\n","131 2015\n","131 2016\n","131 2017\n","131 2018\n","131 2019\n","132 2015\n","132 2016\n","132 2017\n","132 2018\n","132 2019\n","133 2015\n","133 2016\n","133 2017\n","133 2018\n","133 2019\n","134 2015\n","134 2016\n","134 2017\n","134 2018\n","134 2019\n","135 2015\n","135 2016\n","135 2017\n","135 2018\n","135 2019\n","136 2015\n","136 2016\n","136 2017\n","136 2018\n","136 2019\n","137 2015\n","137 2016\n","137 2017\n","137 2018\n","137 2019\n","138 2015\n","138 2016\n","138 2017\n","138 2018\n","138 2019\n","139 2015\n","139 2016\n","139 2017\n","139 2018\n","139 2019\n","140 2015\n","140 2016\n","140 2017\n","140 2018\n","140 2019\n","141 2015\n","141 2016\n","141 2017\n","141 2018\n","141 2019\n","142 2015\n","142 2016\n","142 2017\n","142 2018\n","142 2019\n","143 2015\n","143 2016\n","143 2017\n","143 2018\n","143 2019\n","144 2015\n","144 2016\n","144 2017\n","144 2018\n","144 2019\n","145 2015\n","145 2016\n","145 2017\n","145 2018\n","145 2019\n","146 2015\n","146 2016\n","146 2017\n","146 2018\n","146 2019\n","147 2015\n","147 2016\n","147 2017\n","147 2018\n","147 2019\n","148 2015\n","148 2016\n","148 2017\n","148 2018\n","148 2019\n","149 2015\n","149 2016\n","149 2017\n","149 2018\n","149 2019\n","150 2015\n","150 2016\n","150 2017\n","150 2018\n","150 2019\n","151 2015\n","151 2016\n","151 2017\n","151 2018\n","151 2019\n","152 2015\n","152 2016\n","152 2017\n","152 2018\n","152 2019\n","153 2015\n","153 2016\n","153 2017\n","153 2018\n","153 2019\n","154 2015\n","154 2016\n","154 2017\n","154 2018\n","154 2019\n","155 2015\n","155 2016\n","155 2017\n","155 2018\n","155 2019\n","156 2015\n","156 2016\n","156 2017\n","156 2018\n","156 2019\n","157 2015\n","157 2016\n","157 2017\n","157 2018\n","157 2019\n","158 2015\n","158 2016\n","158 2017\n","158 2018\n","158 2019\n","159 2015\n","159 2016\n","159 2017\n","159 2018\n","159 2019\n","160 2015\n","160 2016\n","160 2017\n","160 2018\n","160 2019\n","161 2015\n","161 2016\n","161 2017\n","161 2018\n","161 2019\n","162 2015\n","162 2016\n","162 2017\n","162 2018\n","162 2019\n","163 2015\n","163 2016\n","163 2017\n","163 2018\n","163 2019\n","164 2015\n","164 2016\n","164 2017\n","164 2018\n","164 2019\n","165 2015\n","165 2016\n","165 2017\n","165 2018\n","165 2019\n","166 2015\n","166 2016\n","166 2017\n","166 2018\n","166 2019\n","167 2015\n","167 2016\n","167 2017\n","167 2018\n","167 2019\n","168 2015\n","168 2016\n","168 2017\n","168 2018\n","168 2019\n","169 2015\n","169 2016\n","169 2017\n","169 2018\n","169 2019\n","170 2015\n","170 2016\n","170 2017\n","170 2018\n","170 2019\n","171 2015\n","171 2016\n","171 2017\n","171 2018\n","171 2019\n","172 2015\n","172 2016\n","172 2017\n","172 2018\n","172 2019\n","173 2015\n","173 2016\n","173 2017\n","173 2018\n","173 2019\n","174 2015\n","174 2016\n","174 2017\n","174 2018\n","174 2019\n","175 2015\n","175 2016\n","175 2017\n","175 2018\n","175 2019\n","176 2015\n","176 2016\n","176 2017\n","176 2018\n","176 2019\n","177 2015\n","177 2016\n","177 2017\n","177 2018\n","177 2019\n","178 2015\n","178 2016\n","178 2017\n","178 2018\n","178 2019\n","179 2015\n","179 2016\n","179 2017\n","179 2018\n","179 2019\n","180 2015\n","180 2016\n","180 2017\n","180 2018\n","180 2019\n","181 2015\n","181 2016\n","181 2017\n","181 2018\n","181 2019\n","182 2015\n","182 2016\n","182 2017\n","182 2018\n","182 2019\n","183 2015\n","183 2016\n","183 2017\n","183 2018\n","183 2019\n","184 2015\n","184 2016\n","184 2017\n","184 2018\n","184 2019\n","185 2015\n","185 2016\n","185 2017\n","185 2018\n","185 2019\n","186 2015\n","186 2016\n","186 2017\n","186 2018\n","186 2019\n","187 2015\n","187 2016\n","187 2017\n","187 2018\n","187 2019\n","188 2015\n","188 2016\n","188 2017\n","188 2018\n","188 2019\n","189 2015\n","189 2016\n","189 2017\n","189 2018\n","189 2019\n","190 2015\n","190 2016\n","190 2017\n","190 2018\n","190 2019\n","191 2015\n","191 2016\n","191 2017\n","191 2018\n","191 2019\n","192 2015\n","192 2016\n","192 2017\n","192 2018\n","192 2019\n","193 2015\n","193 2016\n","193 2017\n","193 2018\n","193 2019\n","194 2015\n","194 2016\n","194 2017\n","194 2018\n","194 2019\n","195 2015\n","195 2016\n","195 2017\n","195 2018\n","195 2019\n","196 2015\n","196 2016\n","196 2017\n","196 2018\n","196 2019\n","197 2015\n","197 2016\n","197 2017\n","197 2018\n","197 2019\n","198 2015\n","198 2016\n","198 2017\n","198 2018\n","198 2019\n","199 2015\n","199 2016\n","199 2017\n","199 2018\n","199 2019\n","200 2015\n","200 2016\n","200 2017\n","200 2018\n","200 2019\n","201 2015\n","201 2016\n","201 2017\n","201 2018\n","201 2019\n","202 2015\n","202 2016\n","202 2017\n","202 2018\n","202 2019\n","203 2015\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["203 2016\n","203 2017\n","203 2018\n","203 2019\n","204 2015\n","204 2016\n","204 2017\n","204 2018\n","204 2019\n","205 2015\n","205 2016\n","205 2017\n","205 2018\n","205 2019\n","206 2015\n","206 2016\n","206 2017\n","206 2018\n","206 2019\n","207 2015\n","207 2016\n","207 2017\n","207 2018\n","207 2019\n","208 2015\n","208 2016\n","208 2017\n","208 2018\n","208 2019\n","209 2015\n","209 2016\n","209 2017\n","209 2018\n","209 2019\n","210 2015\n","210 2016\n","210 2017\n","210 2018\n","210 2019\n","211 2015\n","211 2016\n","211 2017\n","211 2018\n","211 2019\n","212 2015\n","212 2016\n","212 2017\n","212 2018\n","212 2019\n","213 2015\n","213 2016\n","213 2017\n","213 2018\n","213 2019\n","214 2015\n","214 2016\n","214 2017\n","214 2018\n","214 2019\n","215 2015\n","215 2016\n","215 2017\n","215 2018\n","215 2019\n","216 2015\n","216 2016\n","216 2017\n","216 2018\n","216 2019\n","217 2015\n","217 2016\n","217 2017\n","217 2018\n","217 2019\n","218 2015\n","218 2016\n","218 2017\n","218 2018\n","218 2019\n","219 2015\n","219 2016\n","219 2017\n","219 2018\n","219 2019\n","220 2015\n","220 2016\n","220 2017\n","220 2018\n","220 2019\n","221 2015\n","221 2016\n","221 2017\n","221 2018\n","221 2019\n","222 2015\n","222 2016\n","222 2017\n","222 2018\n","222 2019\n","223 2015\n","223 2016\n","223 2017\n","223 2018\n","223 2019\n","224 2015\n","224 2016\n","224 2017\n","224 2018\n","224 2019\n","225 2015\n","225 2016\n","225 2017\n","225 2018\n","225 2019\n","226 2015\n","226 2016\n","226 2017\n","226 2018\n","226 2019\n","227 2015\n","227 2016\n","227 2017\n","227 2018\n","227 2019\n","228 2015\n","228 2016\n","228 2017\n","228 2018\n","228 2019\n","229 2015\n","229 2016\n","229 2017\n","229 2018\n","229 2019\n","230 2015\n","230 2016\n","230 2017\n","230 2018\n","230 2019\n","231 2015\n","231 2016\n","231 2017\n","231 2018\n","231 2019\n","232 2015\n","232 2016\n","232 2017\n","Timeout\n","232 2018\n","232 2019\n","233 2015\n","233 2016\n","233 2017\n","233 2018\n","233 2019\n","234 2015\n","234 2016\n","234 2017\n","234 2018\n","234 2019\n","235 2015\n","235 2016\n","235 2017\n","235 2018\n","235 2019\n","236 2015\n","236 2016\n","236 2017\n","236 2018\n","236 2019\n","237 2015\n","237 2016\n","237 2017\n","237 2018\n","237 2019\n","238 2015\n","238 2016\n","238 2017\n","238 2018\n","238 2019\n","239 2015\n","239 2016\n","239 2017\n","239 2018\n","239 2019\n","240 2015\n","240 2016\n","240 2017\n","240 2018\n","240 2019\n","241 2015\n","241 2016\n","241 2017\n","241 2018\n","241 2019\n","242 2015\n","242 2016\n","242 2017\n","242 2018\n","242 2019\n","243 2015\n","243 2016\n","243 2017\n","243 2018\n","243 2019\n","244 2015\n","244 2016\n","244 2017\n","244 2018\n","244 2019\n","245 2015\n","245 2016\n","245 2017\n","245 2018\n","245 2019\n","246 2015\n","246 2016\n","246 2017\n","246 2018\n","246 2019\n","247 2015\n","247 2016\n","247 2017\n","247 2018\n","247 2019\n","248 2015\n","248 2016\n","248 2017\n","248 2018\n","248 2019\n","249 2015\n","249 2016\n","249 2017\n","249 2018\n","249 2019\n","250 2015\n","250 2016\n","250 2017\n","250 2018\n","250 2019\n","251 2015\n","251 2016\n","251 2017\n","251 2018\n","251 2019\n","252 2015\n","252 2016\n","252 2017\n","252 2018\n","252 2019\n","253 2015\n","253 2016\n","253 2017\n","253 2018\n","253 2019\n","254 2015\n","254 2016\n","254 2017\n","254 2018\n","254 2019\n","255 2015\n","255 2016\n","255 2017\n","255 2018\n","255 2019\n","256 2015\n","256 2016\n","256 2017\n","256 2018\n","256 2019\n","257 2015\n","257 2016\n","257 2017\n","257 2018\n","257 2019\n","258 2015\n","258 2016\n","258 2017\n","258 2018\n","258 2019\n","259 2015\n","259 2016\n","259 2017\n","259 2018\n","259 2019\n","260 2015\n","260 2016\n","260 2017\n","260 2018\n","260 2019\n","261 2015\n","261 2016\n","261 2017\n","261 2018\n","261 2019\n","262 2015\n","262 2016\n","262 2017\n","262 2018\n","Timeout\n","262 2019\n","263 2015\n","263 2016\n","263 2017\n","263 2018\n","263 2019\n","264 2015\n","264 2016\n","264 2017\n","264 2018\n","264 2019\n","265 2015\n","265 2016\n","265 2017\n","265 2018\n","265 2019\n","266 2015\n","266 2016\n","266 2017\n","266 2018\n","266 2019\n","267 2015\n","267 2016\n","267 2017\n","267 2018\n","267 2019\n","268 2015\n","268 2016\n","268 2017\n","268 2018\n","268 2019\n","269 2015\n","269 2016\n","269 2017\n","269 2018\n","269 2019\n","270 2015\n","270 2016\n","270 2017\n","270 2018\n","270 2019\n","271 2015\n","271 2016\n","271 2017\n","271 2018\n","271 2019\n","272 2015\n","272 2016\n","272 2017\n","272 2018\n","272 2019\n","273 2015\n","273 2016\n","273 2017\n","273 2018\n","273 2019\n","274 2015\n","274 2016\n","274 2017\n","274 2018\n","274 2019\n","275 2015\n","275 2016\n","275 2017\n","275 2018\n","275 2019\n","276 2015\n","276 2016\n","276 2017\n","276 2018\n","276 2019\n","277 2015\n","277 2016\n","277 2017\n","277 2018\n","277 2019\n","278 2015\n","278 2016\n","278 2017\n","278 2018\n","278 2019\n","279 2015\n","279 2016\n","279 2017\n","279 2018\n","279 2019\n","280 2015\n","280 2016\n","280 2017\n","280 2018\n","280 2019\n","281 2015\n","281 2016\n","281 2017\n","281 2018\n","281 2019\n","282 2015\n","282 2016\n","282 2017\n","282 2018\n","282 2019\n","283 2015\n","283 2016\n","283 2017\n","283 2018\n","283 2019\n","284 2015\n","284 2016\n","284 2017\n","284 2018\n","284 2019\n","285 2015\n","285 2016\n","285 2017\n","285 2018\n","285 2019\n","286 2015\n","286 2016\n","286 2017\n","286 2018\n","286 2019\n","287 2015\n","287 2016\n","287 2017\n","287 2018\n","287 2019\n","288 2015\n","288 2016\n","288 2017\n","288 2018\n","288 2019\n","289 2015\n","289 2016\n","289 2017\n","289 2018\n","289 2019\n","290 2015\n","290 2016\n","290 2017\n","290 2018\n","290 2019\n","291 2015\n","291 2016\n","291 2017\n","291 2018\n","291 2019\n","292 2015\n","292 2016\n","292 2017\n","292 2018\n","292 2019\n","293 2015\n","293 2016\n","293 2017\n","293 2018\n","293 2019\n","294 2015\n","294 2016\n","294 2017\n","294 2018\n","294 2019\n","295 2015\n","295 2016\n","295 2017\n","295 2018\n","295 2019\n","296 2015\n","296 2016\n","296 2017\n","296 2018\n","296 2019\n","297 2015\n","297 2016\n","297 2017\n","297 2018\n","297 2019\n","298 2015\n","298 2016\n","298 2017\n","298 2018\n","298 2019\n","299 2015\n","299 2016\n","299 2017\n","299 2018\n","299 2019\n","300 2015\n","300 2016\n","300 2017\n","300 2018\n","300 2019\n","301 2015\n","301 2016\n","301 2017\n","301 2018\n","301 2019\n","302 2015\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["302 2016\n","302 2017\n","302 2018\n","302 2019\n","303 2015\n","303 2016\n","303 2017\n","303 2018\n","303 2019\n","304 2015\n","304 2016\n","304 2017\n","304 2018\n","304 2019\n","305 2015\n","305 2016\n","305 2017\n","305 2018\n","305 2019\n","306 2015\n","306 2016\n","306 2017\n","306 2018\n","306 2019\n","307 2015\n","307 2016\n","307 2017\n","307 2018\n","307 2019\n","308 2015\n","308 2016\n","308 2017\n","308 2018\n","308 2019\n","309 2015\n","309 2016\n","309 2017\n","309 2018\n","309 2019\n","310 2015\n","310 2016\n","310 2017\n","310 2018\n","310 2019\n","311 2015\n","311 2016\n","311 2017\n","311 2018\n","311 2019\n","312 2015\n","312 2016\n","312 2017\n","312 2018\n","312 2019\n","313 2015\n","313 2016\n","313 2017\n","313 2018\n","313 2019\n","314 2015\n","314 2016\n","314 2017\n","314 2018\n","314 2019\n","315 2015\n","315 2016\n","315 2017\n","315 2018\n","315 2019\n","316 2015\n","316 2016\n","316 2017\n","316 2018\n","316 2019\n","317 2015\n","317 2016\n","317 2017\n","317 2018\n","317 2019\n","318 2015\n","318 2016\n","318 2017\n","318 2018\n","318 2019\n","319 2015\n","319 2016\n","319 2017\n","319 2018\n","319 2019\n","320 2015\n","320 2016\n","320 2017\n","320 2018\n","320 2019\n","321 2015\n","321 2016\n","321 2017\n","321 2018\n","321 2019\n","322 2015\n","322 2016\n","322 2017\n","322 2018\n","322 2019\n","323 2015\n","323 2016\n","323 2017\n","323 2018\n","323 2019\n","324 2015\n","324 2016\n","324 2017\n","324 2018\n","324 2019\n","325 2015\n","325 2016\n","325 2017\n","325 2018\n","325 2019\n","326 2015\n","326 2016\n","326 2017\n","326 2018\n","326 2019\n","327 2015\n","327 2016\n","327 2017\n","327 2018\n","327 2019\n","328 2015\n","328 2016\n","328 2017\n","328 2018\n","328 2019\n","329 2015\n","329 2016\n","329 2017\n","329 2018\n","329 2019\n","330 2015\n","330 2016\n","330 2017\n","330 2018\n","330 2019\n","331 2015\n","331 2016\n","331 2017\n","331 2018\n","331 2019\n","332 2015\n","332 2016\n","332 2017\n","332 2018\n","332 2019\n","333 2015\n","333 2016\n","333 2017\n","333 2018\n","333 2019\n","334 2015\n","334 2016\n","334 2017\n","334 2018\n","334 2019\n","335 2015\n","335 2016\n","335 2017\n","335 2018\n","335 2019\n","336 2015\n","336 2016\n","336 2017\n","336 2018\n","336 2019\n","337 2015\n","337 2016\n","337 2017\n","337 2018\n","337 2019\n","338 2015\n","338 2016\n","338 2017\n","338 2018\n","338 2019\n","339 2015\n","339 2016\n","339 2017\n","339 2018\n","339 2019\n","340 2015\n","340 2016\n","340 2017\n","340 2018\n","340 2019\n","341 2015\n","341 2016\n","341 2017\n","341 2018\n","341 2019\n","342 2015\n","342 2016\n","342 2017\n","342 2018\n","342 2019\n","343 2015\n","343 2016\n","343 2017\n","343 2018\n","343 2019\n","344 2015\n","344 2016\n","344 2017\n","344 2018\n","344 2019\n","345 2015\n","345 2016\n","345 2017\n","345 2018\n","345 2019\n","346 2015\n","346 2016\n","346 2017\n","346 2018\n","346 2019\n","347 2015\n","347 2016\n","347 2017\n","347 2018\n","347 2019\n","348 2015\n","348 2016\n","348 2017\n","348 2018\n","348 2019\n","349 2015\n","349 2016\n","349 2017\n","349 2018\n","349 2019\n","350 2015\n","350 2016\n","350 2017\n","350 2018\n","350 2019\n","351 2015\n","351 2016\n","351 2017\n","351 2018\n","351 2019\n","352 2015\n","352 2016\n","352 2017\n","352 2018\n","352 2019\n","353 2015\n","353 2016\n","353 2017\n","353 2018\n","353 2019\n","354 2015\n","354 2016\n","354 2017\n","354 2018\n","354 2019\n","355 2015\n","355 2016\n","355 2017\n","355 2018\n","355 2019\n","356 2015\n","356 2016\n","356 2017\n","356 2018\n","356 2019\n","357 2015\n","357 2016\n","357 2017\n","357 2018\n","357 2019\n","358 2015\n","358 2016\n","358 2017\n","358 2018\n","358 2019\n","359 2015\n","359 2016\n","359 2017\n","359 2018\n","359 2019\n","360 2015\n","360 2016\n","360 2017\n","360 2018\n","360 2019\n","361 2015\n","361 2016\n","361 2017\n","361 2018\n","361 2019\n","362 2015\n","362 2016\n","362 2017\n","362 2018\n","362 2019\n","363 2015\n","363 2016\n","363 2017\n","363 2018\n","363 2019\n","364 2015\n","364 2016\n","364 2017\n","364 2018\n","364 2019\n","365 2015\n","365 2016\n","365 2017\n","365 2018\n","365 2019\n","366 2015\n","366 2016\n","366 2017\n","366 2018\n","366 2019\n","367 2015\n","367 2016\n","367 2017\n","367 2018\n","367 2019\n","368 2015\n","368 2016\n","368 2017\n","368 2018\n","368 2019\n","369 2015\n","369 2016\n","369 2017\n","369 2018\n","369 2019\n","370 2015\n","370 2016\n","370 2017\n","370 2018\n","370 2019\n","371 2015\n","371 2016\n","371 2017\n","371 2018\n","371 2019\n","372 2015\n","372 2016\n","372 2017\n","372 2018\n","372 2019\n","373 2015\n","373 2016\n","373 2017\n","373 2018\n","373 2019\n","374 2015\n","374 2016\n","374 2017\n","374 2018\n","374 2019\n","375 2015\n","375 2016\n","375 2017\n","375 2018\n","375 2019\n","376 2015\n","376 2016\n","376 2017\n","376 2018\n","376 2019\n","377 2015\n","377 2016\n","377 2017\n","377 2018\n","377 2019\n","378 2015\n","378 2016\n","378 2017\n","378 2018\n","378 2019\n","379 2015\n","379 2016\n","379 2017\n","379 2018\n","379 2019\n","380 2015\n","380 2016\n","380 2017\n","380 2018\n","380 2019\n","381 2015\n","381 2016\n","381 2017\n","381 2018\n","381 2019\n","382 2015\n","382 2016\n","382 2017\n","382 2018\n","382 2019\n","383 2015\n","383 2016\n","383 2017\n","383 2018\n","383 2019\n","384 2015\n","384 2016\n","384 2017\n","384 2018\n","384 2019\n","385 2015\n","385 2016\n","385 2017\n","385 2018\n","385 2019\n","386 2015\n","386 2016\n","386 2017\n","386 2018\n","386 2019\n","387 2015\n","387 2016\n","387 2017\n","387 2018\n","387 2019\n","388 2015\n","388 2016\n","388 2017\n","388 2018\n","388 2019\n","389 2015\n","389 2016\n","389 2017\n","389 2018\n","389 2019\n","390 2015\n","390 2016\n","390 2017\n","390 2018\n","390 2019\n","391 2015\n","391 2016\n","391 2017\n","391 2018\n","391 2019\n","392 2015\n","392 2016\n","392 2017\n","392 2018\n","392 2019\n","393 2015\n","393 2016\n","393 2017\n","393 2018\n","393 2019\n","394 2015\n","394 2016\n","394 2017\n","394 2018\n","394 2019\n","395 2015\n","395 2016\n","395 2017\n","395 2018\n","395 2019\n","396 2015\n","396 2016\n","396 2017\n","396 2018\n","396 2019\n","397 2015\n","397 2016\n","397 2017\n","397 2018\n","397 2019\n","398 2015\n","398 2016\n","398 2017\n","398 2018\n","398 2019\n","399 2015\n","399 2016\n","399 2017\n","399 2018\n","399 2019\n","400 2015\n","400 2016\n","400 2017\n","400 2018\n","400 2019\n","401 2015\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["401 2016\n","401 2017\n","401 2018\n","401 2019\n","402 2015\n","402 2016\n","402 2017\n","402 2018\n","402 2019\n","403 2015\n","403 2016\n","403 2017\n","403 2018\n","403 2019\n","404 2015\n","404 2016\n","404 2017\n","404 2018\n","404 2019\n","405 2015\n","405 2016\n","405 2017\n","405 2018\n","405 2019\n","406 2015\n","406 2016\n","406 2017\n","406 2018\n","406 2019\n","407 2015\n","407 2016\n","407 2017\n","407 2018\n","407 2019\n","408 2015\n","408 2016\n","408 2017\n","408 2018\n","408 2019\n","409 2015\n","409 2016\n","409 2017\n","409 2018\n","409 2019\n","410 2015\n","410 2016\n","410 2017\n","410 2018\n","410 2019\n","411 2015\n","411 2016\n","411 2017\n","411 2018\n","411 2019\n","412 2015\n","412 2016\n","412 2017\n","412 2018\n","412 2019\n","413 2015\n","413 2016\n","413 2017\n","413 2018\n","413 2019\n","414 2015\n","414 2016\n","414 2017\n","414 2018\n","414 2019\n","415 2015\n","415 2016\n","415 2017\n","415 2018\n","415 2019\n","416 2015\n","416 2016\n","416 2017\n","416 2018\n","416 2019\n","417 2015\n","417 2016\n","417 2017\n","417 2018\n","417 2019\n","418 2015\n","418 2016\n","418 2017\n","418 2018\n","418 2019\n","419 2015\n","419 2016\n","419 2017\n","419 2018\n","419 2019\n","420 2015\n","420 2016\n","420 2017\n","420 2018\n","420 2019\n","421 2015\n","421 2016\n","421 2017\n","421 2018\n","421 2019\n","422 2015\n","422 2016\n","422 2017\n","422 2018\n","422 2019\n","423 2015\n","423 2016\n","423 2017\n","423 2018\n","423 2019\n","424 2015\n","424 2016\n","424 2017\n","424 2018\n","424 2019\n","425 2015\n","425 2016\n","425 2017\n","425 2018\n","425 2019\n","426 2015\n","426 2016\n","426 2017\n","426 2018\n","426 2019\n","427 2015\n","427 2016\n","427 2017\n","427 2018\n","427 2019\n","428 2015\n","428 2016\n","428 2017\n","428 2018\n","428 2019\n","429 2015\n","429 2016\n","429 2017\n","429 2018\n","429 2019\n","430 2015\n","430 2016\n","430 2017\n","430 2018\n","430 2019\n","431 2015\n","431 2016\n","431 2017\n","431 2018\n","431 2019\n","432 2015\n","432 2016\n","432 2017\n","432 2018\n","432 2019\n","433 2015\n","433 2016\n","433 2017\n","433 2018\n","433 2019\n","434 2015\n","434 2016\n","434 2017\n","434 2018\n","434 2019\n","435 2015\n","435 2016\n","435 2017\n","435 2018\n","435 2019\n","436 2015\n","436 2016\n","436 2017\n","436 2018\n","436 2019\n","437 2015\n","437 2016\n","437 2017\n","437 2018\n","437 2019\n","438 2015\n","438 2016\n","438 2017\n","438 2018\n","438 2019\n","439 2015\n","439 2016\n","439 2017\n","439 2018\n","439 2019\n","440 2015\n","440 2016\n","440 2017\n","440 2018\n","440 2019\n","441 2015\n","441 2016\n","441 2017\n","441 2018\n","441 2019\n","442 2015\n","442 2016\n","442 2017\n","442 2018\n","442 2019\n","443 2015\n","443 2016\n","443 2017\n","443 2018\n","443 2019\n","444 2015\n","444 2016\n","444 2017\n","444 2018\n","444 2019\n","445 2015\n","445 2016\n","445 2017\n","445 2018\n","445 2019\n","446 2015\n","446 2016\n","446 2017\n","446 2018\n","446 2019\n","447 2015\n","447 2016\n","447 2017\n","447 2018\n","447 2019\n","448 2015\n","448 2016\n","448 2017\n","448 2018\n","448 2019\n","449 2015\n","449 2016\n","449 2017\n","449 2018\n","449 2019\n","450 2015\n","450 2016\n","450 2017\n","450 2018\n","450 2019\n","451 2015\n","451 2016\n","451 2017\n","451 2018\n","451 2019\n","452 2015\n","452 2016\n","452 2017\n","452 2018\n","452 2019\n","453 2015\n","453 2016\n","453 2017\n","453 2018\n","453 2019\n","454 2015\n","454 2016\n","454 2017\n","454 2018\n","454 2019\n","455 2015\n","455 2016\n","455 2017\n","455 2018\n","455 2019\n","456 2015\n","456 2016\n","456 2017\n","456 2018\n","456 2019\n","457 2015\n","457 2016\n","457 2017\n","457 2018\n","457 2019\n","458 2015\n","458 2016\n","458 2017\n","458 2018\n","458 2019\n","459 2015\n","459 2016\n","459 2017\n","459 2018\n","459 2019\n","460 2015\n","460 2016\n","460 2017\n","460 2018\n","460 2019\n","461 2015\n","461 2016\n","461 2017\n","461 2018\n","461 2019\n","462 2015\n","462 2016\n","462 2017\n","462 2018\n","462 2019\n","463 2015\n","463 2016\n","463 2017\n","463 2018\n","463 2019\n","464 2015\n","464 2016\n","464 2017\n","464 2018\n","464 2019\n","465 2015\n","465 2016\n","465 2017\n","465 2018\n","465 2019\n","466 2015\n","466 2016\n","466 2017\n","466 2018\n","466 2019\n","467 2015\n","467 2016\n","467 2017\n","467 2018\n","467 2019\n","468 2015\n","468 2016\n","468 2017\n","468 2018\n","468 2019\n","469 2015\n","469 2016\n","469 2017\n","469 2018\n","469 2019\n","470 2015\n","470 2016\n","470 2017\n","470 2018\n","470 2019\n","471 2015\n","471 2016\n","471 2017\n","471 2018\n","471 2019\n","472 2015\n","472 2016\n","472 2017\n","472 2018\n","472 2019\n","473 2015\n","473 2016\n","473 2017\n","473 2018\n","473 2019\n","474 2015\n","474 2016\n","474 2017\n","474 2018\n","474 2019\n","475 2015\n","475 2016\n","475 2017\n","475 2018\n","475 2019\n","476 2015\n","476 2016\n","476 2017\n","476 2018\n","476 2019\n","477 2015\n","477 2016\n","477 2017\n","477 2018\n","477 2019\n","478 2015\n","478 2016\n","478 2017\n","478 2018\n","478 2019\n","479 2015\n","479 2016\n","479 2017\n","479 2018\n","479 2019\n","480 2015\n","480 2016\n","480 2017\n","480 2018\n","480 2019\n","481 2015\n","481 2016\n","481 2017\n","481 2018\n","481 2019\n","482 2015\n","482 2016\n","482 2017\n","482 2018\n","482 2019\n","483 2015\n","483 2016\n","483 2017\n","483 2018\n","483 2019\n","484 2015\n","484 2016\n","484 2017\n","484 2018\n","484 2019\n","485 2015\n","485 2016\n","485 2017\n","485 2018\n","485 2019\n","486 2015\n","486 2016\n","486 2017\n","486 2018\n","486 2019\n","487 2015\n","487 2016\n","487 2017\n","487 2018\n","487 2019\n","488 2015\n","488 2016\n","488 2017\n","488 2018\n","488 2019\n","489 2015\n","489 2016\n","489 2017\n","489 2018\n","489 2019\n","490 2015\n","490 2016\n","490 2017\n","490 2018\n","490 2019\n","491 2015\n","491 2016\n","491 2017\n","491 2018\n","491 2019\n","492 2015\n","492 2016\n","492 2017\n","492 2018\n","492 2019\n","493 2015\n","493 2016\n","493 2017\n","493 2018\n","493 2019\n","494 2015\n","494 2016\n","494 2017\n","494 2018\n","494 2019\n","495 2015\n","495 2016\n","495 2017\n","495 2018\n","495 2019\n","496 2015\n","496 2016\n","496 2017\n","496 2018\n","496 2019\n","497 2015\n","497 2016\n","497 2017\n","497 2018\n","497 2019\n","498 2015\n","498 2016\n","498 2017\n","498 2018\n","498 2019\n","499 2015\n","499 2016\n","499 2017\n","499 2018\n","499 2019\n","500 2015\n","500 2016\n","500 2017\n","500 2018\n","500 2019\n","501 2015\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["501 2016\n","501 2017\n","501 2018\n","501 2019\n","502 2015\n","502 2016\n","502 2017\n","502 2018\n","502 2019\n","503 2015\n","503 2016\n","503 2017\n","503 2018\n","503 2019\n","504 2015\n","504 2016\n","504 2017\n","504 2018\n","504 2019\n","505 2015\n","505 2016\n","505 2017\n","505 2018\n","505 2019\n","506 2015\n","506 2016\n","506 2017\n","506 2018\n","506 2019\n","507 2015\n","507 2016\n","507 2017\n","507 2018\n","507 2019\n","508 2015\n","508 2016\n","508 2017\n","508 2018\n","508 2019\n","509 2015\n","509 2016\n","509 2017\n","509 2018\n","509 2019\n","510 2015\n","510 2016\n","510 2017\n","510 2018\n","510 2019\n","511 2015\n","511 2016\n","511 2017\n","511 2018\n","511 2019\n","512 2015\n","512 2016\n","512 2017\n","512 2018\n","512 2019\n","513 2015\n","513 2016\n","513 2017\n","513 2018\n","513 2019\n","514 2015\n","514 2016\n","514 2017\n","514 2018\n","514 2019\n","515 2015\n","515 2016\n","515 2017\n","515 2018\n","515 2019\n","516 2015\n","516 2016\n","516 2017\n","516 2018\n","516 2019\n","517 2015\n","517 2016\n","517 2017\n","517 2018\n","517 2019\n","518 2015\n","518 2016\n","518 2017\n","518 2018\n","518 2019\n","519 2015\n","519 2016\n","519 2017\n","519 2018\n","519 2019\n","520 2015\n","520 2016\n","520 2017\n","520 2018\n","520 2019\n","521 2015\n","521 2016\n","521 2017\n","521 2018\n","521 2019\n","522 2015\n","522 2016\n","522 2017\n","522 2018\n","522 2019\n","523 2015\n","523 2016\n","523 2017\n","523 2018\n","523 2019\n","524 2015\n","524 2016\n","524 2017\n","524 2018\n","524 2019\n","525 2015\n","525 2016\n","525 2017\n","525 2018\n","525 2019\n","526 2015\n","526 2016\n","526 2017\n","526 2018\n","526 2019\n","527 2015\n","527 2016\n","527 2017\n","527 2018\n","527 2019\n","528 2015\n","528 2016\n","528 2017\n","528 2018\n","528 2019\n","529 2015\n","529 2016\n","529 2017\n","529 2018\n","529 2019\n","530 2015\n","530 2016\n","530 2017\n","530 2018\n","530 2019\n","531 2015\n","531 2016\n","531 2017\n","531 2018\n","531 2019\n","532 2015\n","532 2016\n","532 2017\n","532 2018\n","532 2019\n","533 2015\n","533 2016\n","533 2017\n","533 2018\n","533 2019\n","534 2015\n","534 2016\n","534 2017\n","534 2018\n","534 2019\n","535 2015\n","535 2016\n","535 2017\n","535 2018\n","535 2019\n","536 2015\n","536 2016\n","536 2017\n","536 2018\n","536 2019\n","537 2015\n","537 2016\n","537 2017\n","537 2018\n","537 2019\n","538 2015\n","538 2016\n","538 2017\n","538 2018\n","538 2019\n","539 2015\n","539 2016\n","539 2017\n","539 2018\n","539 2019\n","540 2015\n","540 2016\n","540 2017\n","540 2018\n","540 2019\n","541 2015\n","541 2016\n","541 2017\n","541 2018\n","541 2019\n","542 2015\n","542 2016\n","542 2017\n","542 2018\n","542 2019\n","543 2015\n","543 2016\n","543 2017\n","543 2018\n","543 2019\n","544 2015\n","544 2016\n","544 2017\n","544 2018\n","544 2019\n","545 2015\n","545 2016\n","545 2017\n","545 2018\n","545 2019\n","546 2015\n","546 2016\n","546 2017\n","546 2018\n","546 2019\n","547 2015\n","547 2016\n","547 2017\n","547 2018\n","547 2019\n","548 2015\n","548 2016\n","548 2017\n","548 2018\n","548 2019\n","549 2015\n","549 2016\n","549 2017\n","549 2018\n","549 2019\n","550 2015\n","550 2016\n","550 2017\n","550 2018\n","550 2019\n","551 2015\n","551 2016\n","551 2017\n","551 2018\n","551 2019\n","552 2015\n","552 2016\n","552 2017\n","552 2018\n","552 2019\n","553 2015\n","553 2016\n","553 2017\n","553 2018\n","553 2019\n","554 2015\n","554 2016\n","554 2017\n","554 2018\n","554 2019\n","555 2015\n","555 2016\n","555 2017\n","555 2018\n","555 2019\n","556 2015\n","556 2016\n","556 2017\n","556 2018\n","556 2019\n","557 2015\n","557 2016\n","557 2017\n","557 2018\n","557 2019\n","558 2015\n","558 2016\n","558 2017\n","558 2018\n","558 2019\n","559 2015\n","559 2016\n","559 2017\n","559 2018\n","559 2019\n","560 2015\n","560 2016\n","560 2017\n","560 2018\n","560 2019\n","561 2015\n","561 2016\n","561 2017\n","561 2018\n","561 2019\n","562 2015\n","562 2016\n","562 2017\n","562 2018\n","562 2019\n","563 2015\n","563 2016\n","563 2017\n","563 2018\n","563 2019\n","564 2015\n","564 2016\n","564 2017\n","564 2018\n","564 2019\n","565 2015\n","565 2016\n","565 2017\n","565 2018\n","565 2019\n","566 2015\n","566 2016\n","566 2017\n","566 2018\n","566 2019\n","567 2015\n","567 2016\n","567 2017\n","567 2018\n","567 2019\n","568 2015\n","568 2016\n","568 2017\n","568 2018\n","568 2019\n","569 2015\n","569 2016\n","569 2017\n","569 2018\n","569 2019\n","570 2015\n","570 2016\n","570 2017\n","570 2018\n","570 2019\n","571 2015\n","571 2016\n","571 2017\n","571 2018\n","571 2019\n","572 2015\n","572 2016\n","572 2017\n","572 2018\n","572 2019\n","573 2015\n","573 2016\n","573 2017\n","573 2018\n","573 2019\n","574 2015\n","574 2016\n","574 2017\n","574 2018\n","574 2019\n","575 2015\n","575 2016\n","575 2017\n","575 2018\n","575 2019\n","576 2015\n","576 2016\n","576 2017\n","576 2018\n","576 2019\n","577 2015\n","577 2016\n","577 2017\n","577 2018\n","577 2019\n","578 2015\n","578 2016\n","578 2017\n","578 2018\n","578 2019\n","579 2015\n","579 2016\n","579 2017\n","579 2018\n","579 2019\n","580 2015\n","580 2016\n","580 2017\n","580 2018\n","580 2019\n","581 2015\n","581 2016\n","581 2017\n","581 2018\n","581 2019\n","582 2015\n","582 2016\n","582 2017\n","582 2018\n","582 2019\n","583 2015\n","583 2016\n","583 2017\n","583 2018\n","583 2019\n","584 2015\n","584 2016\n","584 2017\n","584 2018\n","584 2019\n","585 2015\n","585 2016\n","585 2017\n","585 2018\n","585 2019\n","586 2015\n","586 2016\n","586 2017\n","586 2018\n","586 2019\n","587 2015\n","587 2016\n","587 2017\n","587 2018\n","587 2019\n","588 2015\n","588 2016\n","588 2017\n","588 2018\n","588 2019\n","589 2015\n","589 2016\n","589 2017\n","589 2018\n","589 2019\n","590 2015\n","590 2016\n","590 2017\n","590 2018\n","590 2019\n","591 2015\n","591 2016\n","591 2017\n","591 2018\n","591 2019\n","592 2015\n","592 2016\n","592 2017\n","592 2018\n","592 2019\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IMxGoeYrIUcQ","outputId":"b0dfd22f-3db5-4d0b-b1c0-0210c53bc22a"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/annualData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","rows_list = []\n","n = 0\n","location = pd.DataFrame(columns=['fips', 'lat', 'long', 'site_address', 'local_site_name', 'state', 'county', 'city'])\n","for i in range(0, len(bufflist)):\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='44201',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=bufflist[i][0:2],\n","        county=bufflist[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=10)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      val = []\n","      loc = []\n","      listdata = data['Data']\n","      for j in listdata:\n","        val.append(j['arithmetic_mean'])\n","        loc.append({'fips' : bufflist[i], 'lat': j['latitude'], 'long': j['longitude'], 'site_address': j['site_address'], 'local_site_name': j['local_site_name'], 'state': j['state'], 'county': j['county'], 'city': j['city']})\n","      # val\n","      location = location.append(loc)\n","      rows_list.append({'ozone': np.mean(val), 'year': year, 'fips': bufflist[i]})\n","    except:\n","      print('Problem with '+ bufflist[i] + ' year ' + year)\n","  if (i % 100 == 0) and (i != 0):\n","    ozonedf = pd.DataFrame(rows_list)\n","    rows_list = []\n","    t = ozonedf.groupby('fips').mean()\n","    t = t.dropna()\n","    t.to_csv('ozone_'+str(n)+'.csv') \n","    n += 1\n","\n","ozonedf = pd.DataFrame(rows_list)\n","t = ozonedf.groupby('fips').mean()\n","t = t.dropna()\n","t.to_csv('ozone_'+str(n)+'.csv') \n","n += 1\n","\n","location = location.drop_duplicates()\n","location.to_csv('ozone_location.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 2015\n","0 2016\n","0 2017\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"},{"output_type":"stream","text":["0 2018\n","0 2019\n","1 2015\n","1 2016\n","1 2017\n","1 2018\n","1 2019\n","2 2015\n","2 2016\n","2 2017\n","2 2018\n","2 2019\n","3 2015\n","3 2016\n","3 2017\n","3 2018\n","3 2019\n","4 2015\n","4 2016\n","4 2017\n","4 2018\n","4 2019\n","5 2015\n","5 2016\n","5 2017\n","5 2018\n","5 2019\n","6 2015\n","6 2016\n","6 2017\n","6 2018\n","6 2019\n","7 2015\n","7 2016\n","7 2017\n","7 2018\n","7 2019\n","8 2015\n","8 2016\n","8 2017\n","8 2018\n","8 2019\n","9 2015\n","9 2016\n","9 2017\n","9 2018\n","9 2019\n","10 2015\n","10 2016\n","10 2017\n","10 2018\n","10 2019\n","11 2015\n","11 2016\n","11 2017\n","11 2018\n","11 2019\n","12 2015\n","12 2016\n","12 2017\n","12 2018\n","12 2019\n","13 2015\n","13 2016\n","13 2017\n","13 2018\n","13 2019\n","14 2015\n","14 2016\n","14 2017\n","14 2018\n","14 2019\n","15 2015\n","15 2016\n","15 2017\n","15 2018\n","15 2019\n","16 2015\n","16 2016\n","16 2017\n","16 2018\n","16 2019\n","17 2015\n","17 2016\n","17 2017\n","17 2018\n","17 2019\n","18 2015\n","18 2016\n","18 2017\n","18 2018\n","18 2019\n","19 2015\n","19 2016\n","19 2017\n","19 2018\n","19 2019\n","20 2015\n","20 2016\n","20 2017\n","20 2018\n","20 2019\n","21 2015\n","21 2016\n","21 2017\n","21 2018\n","21 2019\n","22 2015\n","22 2016\n","22 2017\n","22 2018\n","22 2019\n","23 2015\n","23 2016\n","23 2017\n","23 2018\n","23 2019\n","24 2015\n","24 2016\n","24 2017\n","24 2018\n","24 2019\n","25 2015\n","25 2016\n","25 2017\n","25 2018\n","25 2019\n","26 2015\n","26 2016\n","26 2017\n","26 2018\n","26 2019\n","27 2015\n","27 2016\n","27 2017\n","27 2018\n","27 2019\n","28 2015\n","28 2016\n","28 2017\n","28 2018\n","28 2019\n","29 2015\n","29 2016\n","29 2017\n","29 2018\n","29 2019\n","30 2015\n","30 2016\n","30 2017\n","30 2018\n","30 2019\n","31 2015\n","31 2016\n","31 2017\n","31 2018\n","31 2019\n","32 2015\n","32 2016\n","32 2017\n","32 2018\n","32 2019\n","33 2015\n","33 2016\n","33 2017\n","33 2018\n","33 2019\n","34 2015\n","34 2016\n","34 2017\n","34 2018\n","34 2019\n","35 2015\n","35 2016\n","35 2017\n","35 2018\n","35 2019\n","36 2015\n","36 2016\n","36 2017\n","36 2018\n","36 2019\n","37 2015\n","37 2016\n","37 2017\n","37 2018\n","37 2019\n","38 2015\n","38 2016\n","38 2017\n","38 2018\n","38 2019\n","39 2015\n","39 2016\n","39 2017\n","39 2018\n","39 2019\n","40 2015\n","40 2016\n","40 2017\n","40 2018\n","40 2019\n","41 2015\n","41 2016\n","41 2017\n","41 2018\n","41 2019\n","42 2015\n","42 2016\n","42 2017\n","42 2018\n","42 2019\n","43 2015\n","43 2016\n","43 2017\n","43 2018\n","43 2019\n","44 2015\n","44 2016\n","44 2017\n","44 2018\n","44 2019\n","45 2015\n","45 2016\n","45 2017\n","45 2018\n","45 2019\n","46 2015\n","46 2016\n","46 2017\n","46 2018\n","46 2019\n","47 2015\n","47 2016\n","47 2017\n","47 2018\n","47 2019\n","48 2015\n","48 2016\n","48 2017\n","48 2018\n","48 2019\n","Timeout\n","49 2015\n","49 2016\n","49 2017\n","49 2018\n","49 2019\n","50 2015\n","50 2016\n","50 2017\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-19bc03251cb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mcounty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbufflist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"QmKaibiVW9T3"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/annualData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","rows_list = []\n","n = 0\n","location = pd.DataFrame(columns=['fips', 'lat', 'long', 'site_address', 'local_site_name', 'state', 'county', 'city'])\n","for i in range(0, len(bufflist)):\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='88101',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=bufflist[i][0:2],\n","        county=bufflist[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=10)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      val = []\n","      loc = []\n","      listdata = data['Data']\n","      for j in listdata:\n","        val.append(j['arithmetic_mean'])\n","        loc.append({'fips' : bufflist[i], 'lat': j['latitude'], 'long': j['longitude'], 'site_address': j['site_address'], 'local_site_name': j['local_site_name'], 'state': j['state'], 'county': j['county'], 'city': j['city']})\n","      # val\n","      location = location.append(loc)\n","      rows_list.append({'pm25': np.mean(val), 'year': year, 'fips': bufflist[i]})\n","    except:\n","      print('Problem with '+ bufflist[i] + ' year ' + year)\n","  if (i % 100 == 0) and (i != 0):\n","    pm25df = pd.DataFrame(rows_list)\n","    rows_list = []\n","    t = pm25df.groupby('fips').mean()\n","    t = t.dropna()\n","    t.to_csv('pm25_'+str(n)+'.csv') \n","    n += 1\n","\n","pm25df = pd.DataFrame(rows_list)\n","t = pm25df.groupby('fips').mean()\n","t = t.dropna()\n","t.to_csv('pm25_'+str(n)+'.csv') \n","n += 1\n","\n","location = location.drop_duplicates()\n","location.to_csv('pm25_location.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISN-mX1stRjy"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/annualData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/annualData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","rows_list = []\n","n = 0\n","location = pd.DataFrame(columns=['fips', 'lat', 'long', 'site_address', 'local_site_name', 'state', 'county', 'city'])\n","for i in range(0, len(bufflist)):\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='42401',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=bufflist[i][0:2],\n","        county=bufflist[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=10)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      val = []\n","      loc = []\n","      listdata = data['Data']\n","      for j in listdata:\n","        val.append(j['arithmetic_mean'])\n","        loc.append({'fips' : bufflist[i], 'lat': j['latitude'], 'long': j['longitude'], 'site_address': j['site_address'], 'local_site_name': j['local_site_name'], 'state': j['state'], 'county': j['county'], 'city': j['city']})\n","      # val\n","      location = location.append(loc)\n","      rows_list.append({'so2': np.mean(val), 'year': year, 'fips': bufflist[i]})\n","    except:\n","      print('Problem with '+ bufflist[i] + ' year ' + year)\n","  if (i % 100 == 0) and (i != 0):\n","    so2df = pd.DataFrame(rows_list)\n","    rows_list = []\n","    t = so2df.groupby('fips').mean()\n","    t = t.dropna()\n","    t.to_csv('so2_'+str(n)+'.csv')\n","    n += 1\n","\n","so2df = pd.DataFrame(rows_list)\n","t = so2df.groupby('fips').mean()\n","t = t.dropna()\n","t.to_csv('so2_'+str(n)+'.csv') \n","n += 1\n","\n","location = location.drop_duplicates()\n","location.to_csv('so2_location.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BclsKyHk41K7"},"source":["## Time series"]},{"cell_type":"code","metadata":{"id":"4uSGNOgJUYfR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640179741851,"user_tz":-420,"elapsed":2570,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"018d31ba-d2a2-4c24-c4d1-5daccaefcaee"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"QRSjogmw599Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640179742535,"user_tz":-420,"elapsed":688,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"990d82d7-ac0d-4fcc-a529-1a7e034a2bf7"},"source":["import pandas as pd\n","\n","cdata = pd.read_csv(\"/content/drive/My Drive/COVID19_Cities/Data/cdata.csv\")\n","cdata = cdata.drop('Unnamed: 0', axis=1)\n","cdata['fips'] = cdata['fips'].astype(int).astype(str).apply(lambda x: x.zfill(5)[0:5])\n","cdatafips = cdata['fips'].tolist()\n","len(cdatafips)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["174"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"u0wgxOSE5iKf","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"error","timestamp":1640179744869,"user_tz":-420,"elapsed":2338,"user":{"displayName":"Chaya Chaipitakporn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAxSGUqho-1Diepkf7oVicz7wCe0RU1YtfoUAc=s64","userId":"01290764672070272128"}},"outputId":"41325924-61c4-4aef-c874-adf2d970dd36"},"source":["import requests\n","import time\n","import numpy as np\n","\n","ay = pd.DataFrame(columns=['sample_measurement'])\n","ay.index.name = 'date_gmt'\n","\n","resp = requests.get(url= 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20150101&edate=20151231&state=04&county=001')\n","data = resp.json()\n","\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[t['sample_duration'] == '24 HOUR']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","\n","resp = requests.get(url= 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=04&county=001')\n","data = resp.json()\n","\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[t['sample_duration'] == '24 HOUR']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","resp = requests.get(url= 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20170101&edate=20171231&state=04&county=001')\n","data = resp.json()\n","\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[t['sample_duration'] == '24 HOUR']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","resp = requests.get(url= 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20180101&edate=20181231&state=04&county=001')\n","data = resp.json()\n","\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[t['sample_duration'] == '24 HOUR']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","resp = requests.get(url= 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20190101&edate=20191231&state=04&county=001')\n","data = resp.json()\n","\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[t['sample_duration'] == '24 HOUR']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","ay = ay.groupby(ay.index).mean()\n","\n","dlist = ay.index.tolist()"],"execution_count":5,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-dc06cfba9d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=04&county=001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"WZKhfay0UMIN"},"source":["# https://aqs.epa.gov/aqsweb/documents/data_api.html#terms\n","''' \n","    {\n","      \"code\": \"14129\",\n","      \"value_represented\": \"Lead (TSP) LC\"\n","    },\n","    {\n","      \"code\": \"42101\",\n","      \"value_represented\": \"Carbon monoxide\"\n","    },\n","    {\n","      \"code\": \"42401\",\n","      \"value_represented\": \"Sulfur dioxide\"\n","    },\n","    {\n","      \"code\": \"42602\",\n","      \"value_represented\": \"Nitrogen dioxide (NO2)\"\n","    },\n","    {\n","      \"code\": \"44201\",\n","      \"value_represented\": \"Ozone\"\n","    },\n","    {\n","      \"code\": \"81102\",\n","      \"value_represented\": \"PM10 Total 0-10um STP\"\n","    },\n","    {\n","      \"code\": \"85129\",\n","      \"value_represented\": \"Lead PM10 LC FRM/FEM\"\n","    },\n","    {\n","      \"code\": \"88101\",\n","      \"value_represented\": \"PM2.5 - Local Conditions\"\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ob3_Rv-r43nE"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/sampleData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","pmfinresult = pd.DataFrame({'date_gmt': dlist})\n","pmfinresult.set_index('date_gmt')\n","\n","rows_list = []\n","n = 0\n","for i in range(0, len(cdatafips)):\n","# for i in range(0, 2):\n","  ay = pd.DataFrame(columns=['sample_measurement'])\n","  ay.index.name = 'date_gmt'\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='88101',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=cdatafips[i][0:2],\n","        county=cdatafips[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=30)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","      t['fips'] = t['state_code'] + t['county_code']\n","      t = t[['date_gmt', 'fips', 'sample_measurement']]\n","      t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","      t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","      ay = pd.concat([ay,t]).drop_duplicates()\n","      \n","    except:\n","      print('Problem with '+ cdatafips[i] + ' year ' + year)\n","\n","  ay = ay.rename(columns = {'sample_measurement' : cdatafips[i]})\n","  pmfinresult = pmfinresult.merge(ay, on='date_gmt', how='outer')\n","  if (i % 5 == 0) and (i != 0):\n","    pmfinresult.to_csv('pm25_time_'+str(n)+'.csv') \n","    pmfinresult = pd.DataFrame({'date_gmt': dlist})\n","    pmfinresult.set_index('date_gmt')\n","    n += 1\n","\n","pmfinresult.to_csv('pm25_time_'+str(n)+'.csv')\n","print('done')\n","# pm25df = pd.DataFrame(rows_list)\n","# t = pm25df.groupby('fips').mean()\n","# t = t.dropna()\n","# n += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yNTJSOd1SYh"},"source":["import requests\n","import pandas as pd\n","\n","cofinresult = pd.DataFrame({'date_gmt': dlist})\n","cofinresult.set_index('date_gmt')\n","\n","url = 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=42101&bdate=20150101&edate=20151231&state=04&county=013'\n","\n","ay = pd.DataFrame(columns=['sample_measurement'])\n","ay.index.name = 'date_gmt'\n","\n","resp = requests.get(url=url)\n","data = resp.json()\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","url = 'https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=42101&bdate=20160101&edate=20161231&state=04&county=013'\n","\n","resp = requests.get(url=url)\n","data = resp.json()\n","t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","t['fips'] = t['state_code'] + t['county_code']\n","t = t[['date_gmt', 'fips', 'sample_measurement']]\n","t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","ay = pd.concat([ay,t]).drop_duplicates()\n","\n","cofinresult = cofinresult.merge(ay, on='date_gmt', how='outer')\n","cofinresult"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EuAOwLmVFzd"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/sampleData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","no2finresult = pd.DataFrame({'date_gmt': dlist})\n","no2finresult.set_index('date_gmt')\n","\n","rows_list = []\n","n = 0\n","for i in range(0, len(cdatafips)):\n","# for i in range(0, 2):\n","  ay = pd.DataFrame(columns=['sample_measurement'])\n","  ay.index.name = 'date_gmt'\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='42602',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=cdatafips[i][0:2],\n","        county=cdatafips[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=30)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","      t['fips'] = t['state_code'] + t['county_code']\n","      t = t[['date_gmt', 'fips', 'sample_measurement']]\n","      t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","      t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","      ay = pd.concat([ay,t]).drop_duplicates()\n","      \n","    except:\n","      print('Problem with '+ cdatafips[i] + ' year ' + year)\n","\n","  ay = ay.rename(columns = {'sample_measurement' : cdatafips[i]})\n","  no2finresult = no2finresult.merge(ay, on='date_gmt', how='outer')\n","  if (i % 5 == 0) and (i != 0):\n","    no2finresult.to_csv('no2_time_'+str(n)+'.csv') \n","    no2finresult = pd.DataFrame({'date_gmt': dlist})\n","    no2finresult.set_index('date_gmt')\n","    n += 1\n","\n","no2finresult.to_csv('no2_time_'+str(n)+'.csv')\n","print('done')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1Z60qCzVa_9"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/sampleData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","ozonefinresult = pd.DataFrame({'date_gmt': dlist})\n","ozonefinresult.set_index('date_gmt')\n","\n","rows_list = []\n","n = 0\n","for i in range(0, len(cdatafips)):\n","# for i in range(0, 2):\n","  ay = pd.DataFrame(columns=['sample_measurement'])\n","  ay.index.name = 'date_gmt'\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='44201',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=cdatafips[i][0:2],\n","        county=cdatafips[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=30)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","      t['fips'] = t['state_code'] + t['county_code']\n","      t = t[['date_gmt', 'fips', 'sample_measurement']]\n","      t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","      t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","      ay = pd.concat([ay,t]).drop_duplicates()\n","      \n","    except:\n","      print('Problem with '+ cdatafips[i] + ' year ' + year)\n","\n","  ay = ay.rename(columns = {'sample_measurement' : cdatafips[i]})\n","  ozonefinresult = ozonefinresult.merge(ay, on='date_gmt', how='outer')\n","  if (i % 5 == 0) and (i != 0):\n","    ozonefinresult.to_csv('ozone_time_'+str(n)+'.csv') \n","    ozonefinresult = pd.DataFrame({'date_gmt': dlist})\n","    ozonefinresult.set_index('date_gmt')\n","    n += 1\n","\n","ozonefinresult.to_csv('ozone_time_'+str(n)+'.csv')\n","print('done')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTIopyA1VZLz"},"source":["import requests\n","import time\n","import numpy as np\n","from google.colab import files\n","\n","# https://aqs.epa.gov/data/api/sampleData/byCounty?email=chaipic@clarkson.edu&key=silverfox96&param=88101,88502&bdate=20160101&edate=20161231&state=37&county=183\n","url = 'https://aqs.epa.gov/data/api/sampleData/byCounty'\n","years = ['2015', '2016', '2017', '2018', '2019']\n","\n","so2finresult = pd.DataFrame({'date_gmt': dlist})\n","so2finresult.set_index('date_gmt')\n","\n","rows_list = []\n","n = 0\n","for i in range(0, len(cdatafips)):\n","# for i in range(0, 2):\n","  ay = pd.DataFrame(columns=['sample_measurement'])\n","  ay.index.name = 'date_gmt'\n","  for year in years:\n","    # print(i, year)\n","    params = dict(\n","        email='chaipic@clarkson.edu',\n","        key='silverfox96',\n","        param='42401',\n","        bdate=year + '0101',\n","        edate=year + '1231',\n","        state=cdatafips[i][0:2],\n","        county=cdatafips[i][2:5]\n","    )\n","    time.sleep(0.01)\n","    try:\n","      resp = requests.get(url=url, params=params, timeout=30)\n","      data = resp.json()\n","    except:\n","      print('Timeout')\n","    try:\n","      t = pd.DataFrame(data['Data']) # Micrograms/cubic meter (LC)\n","      t['fips'] = t['state_code'] + t['county_code']\n","      t = t[['date_gmt', 'fips', 'sample_measurement']]\n","      t['date_gmt'] = pd.to_datetime(t['date_gmt'])\n","      t = t.groupby(pd.Grouper(key='date_gmt', freq='W-MON')).mean()\n","      ay = pd.concat([ay,t]).drop_duplicates()\n","      \n","    except:\n","      print('Problem with '+ cdatafips[i] + ' year ' + year)\n","\n","  ay = ay.rename(columns = {'sample_measurement' : cdatafips[i]})\n","  so2finresult = so2finresult.merge(ay, on='date_gmt', how='outer')\n","  if (i % 5 == 0) and (i != 0):\n","    so2finresult.to_csv('so2_time_'+str(n)+'.csv') \n","    so2finresult = pd.DataFrame({'date_gmt': dlist})\n","    so2finresult.set_index('date_gmt')\n","    n += 1\n","\n","so2finresult.to_csv('so2_time_'+str(n)+'.csv')\n","print('done')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxMw56QZtH2S"},"source":[""],"execution_count":null,"outputs":[]}]}